{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Q-learning\n",
    "In this notebook, we'll build a neural network that can learn to play games through reinforcement learning. More specifically, we'll use Q-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-19 14:50:58,477] Making new env: CartPole-v0\n"
     ]
    }
   ],
   "source": [
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to watch the simulation run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env.reset()\n",
    "rewards = []\n",
    "for _ in range(100):\n",
    "    # use env.render() to render one frame\n",
    "    env.render()\n",
    "    # env.step will generate the next step in the simulation\n",
    "    state, reward, done, info = env.step(env.action_space.sample())\n",
    "    rewards.append(reward)\n",
    "    if done:\n",
    "        rewards = []\n",
    "        env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network\n",
    "\n",
    "We train our Q-learning agent using the Bellman Equation:\n",
    "\n",
    "$$\n",
    "Q(s, a) = r + \\gamma \\max{Q(s', a')}\n",
    "$$\n",
    "\n",
    "where $s$ is a state, $a$ is an action, and $s'$ is the next state from state $s$ and action $a$.\n",
    "\n",
    "Before we used this equation to learn values for a Q-_table_. However, for this game there are a huge number of states available. The state has four values: the position and velocity of the cart, and the position and velocity of the pole. Instead of using a table then, we'll replace it with a neural network that will approximate the Q-table lookup function.\n",
    "\n",
    "Now, our Q value, $Q(s, a)$ is calculated by passing in a state to the network. The output will be Q-values for each available action, with fully connected hidden layers.\n",
    "\n",
    "As I showed before, we can define our targets for training as $\\hat{Q}(s,a) = r + \\gamma \\max{Q(s', a')}$. Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "For this Cart-Pole game, we have four inputs, one for each value in the state, and two outputs, one for each action. To get $\\hat{Q}$, we'll first choose an action, then simulate the game using that action. This will get us the next state, $s'$, and the reward. With that, we can calculate $\\hat{Q}$ then pass it back into the $Q$ network to run the optimizer and update the weights.\n",
    "\n",
    "Below is my implementation of the Q-network. I used two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QNetwork:\n",
    "    def __init__(self, learning_rate = 0.01, \n",
    "                 state_size = 4, \n",
    "                 action_size = 2, \n",
    "                 hidden_size = 10, \n",
    "                 name = 'QNetwork'):\n",
    "        with tf.variable_scope(name):\n",
    "            self.inputs_ = tf.placeholder(tf.float32, [None, state_size], name = 'inputs')\n",
    "            \n",
    "            # One hot encode the actions to later choose the Q-value for the action\n",
    "            self.actions_ = tf.placeholder(tf.int32, [None], name = 'actions')\n",
    "            one_hot_actions = tf.one_hot(self.actions_, action_size)\n",
    "            \n",
    "            # Target Q values for training\n",
    "            self.targetQs_ = tf.placeholder(tf.float32, [None], name='target')\n",
    "            \n",
    "            # ReLU hidden layers\n",
    "            self.fc1 = tf.contrib.layers.fully_connected(self.inputs_, hidden_size)\n",
    "            self.fc2 = tf.contrib.layers.fully_connected(self.fc1, hidden_size)\n",
    "\n",
    "            # Linear output layer\n",
    "            self.output = tf.contrib.layers.fully_connected(self.fc2, action_size, \n",
    "                                                            activation_fn=None)\n",
    "            ### Train with loss (targetQ - Q)^2\n",
    "            self.Q = tf.reduce_sum(tf.multiply(self.output, one_hot_actions), axis=1)\n",
    "            \n",
    "            self.loss = tf.reduce_mean(tf.square(self.targetQs_ - self.Q))\n",
    "            self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to **correlations between states**. To reduce correlations when training, we can store the agent's experiences and later **draw a random mini-batch** of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maxmium capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "class Memory():\n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen = max_size)\n",
    "        \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)),\n",
    "                               size = batch_size,\n",
    "                               replace = True)\n",
    "        return [self.buffer[i] for i in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Exploitation\n",
    "\n",
    "To learn about the environment and rules of the game, the agent needs to explore by taking random actions. We'll do this by choosing a random action with some probability $\\epsilon$ (epsilon).  That is, with some probability $\\epsilon$ the agent will make a random action and with probability $1 - \\epsilon$, the agent will choose an action from $Q(s,a)$. This is called an **$\\epsilon$-greedy policy**.\n",
    "\n",
    "\n",
    "At first, the agent needs to do a lot of exploring. Later when it has learned more, the agent can favor choosing actions based on what it has learned. This is called _exploitation_. We'll set it up so the agent is more likely to explore early in training, then more likely to exploit later in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning training algorithm\n",
    "\n",
    "Putting all this together, we can list out the algorithm we'll use to train the network. We'll train the network in _episodes_. One *episode* is one simulation of the game. For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode = 1, $M$ **do**\n",
    "  * **For** $t$, $T$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Environmnet parameters\n",
    "train_episodes = 1000\n",
    "max_steps = 200\n",
    "gamma = 0.99\n",
    "\n",
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer\n",
    "learning_rate = 0.0001         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 10000            # memory capacity\n",
    "batch_size = 20                # experience mini-batch size\n",
    "pretrain_length = batch_size   # number experiences to pretrain the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = QNetwork(name='main', hidden_size=hidden_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the experience memory\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env.reset()\n",
    "# Take one random step to get the pole and cart moving\n",
    "state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "memory = Memory(max_size = memory_size)\n",
    "# Make a bunch of random actions and store the experiences\n",
    "for ii in range(pretrain_length):\n",
    "    # env.render()\n",
    "    # Make a random action\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "    if done:\n",
    "        # The simulation fails so no next state\n",
    "        next_state = np.zeros(state.shape)\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        \n",
    "        # Start new episode\n",
    "        env.reset()\n",
    "        # Take one random step to get the pole and cart moving\n",
    "        state, reward, done, _ = env.step(env.action_space.sample())\n",
    "    else:\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 Total reward: 12.0 Training loss: 1.1326 Explore P: 0.9988\n",
      "Episode: 2 Total reward: 32.0 Training loss: 1.0374 Explore P: 0.9957\n",
      "Episode: 3 Total reward: 15.0 Training loss: 1.0326 Explore P: 0.9942\n",
      "Episode: 4 Total reward: 17.0 Training loss: 1.1072 Explore P: 0.9925\n",
      "Episode: 5 Total reward: 13.0 Training loss: 1.0962 Explore P: 0.9912\n",
      "Episode: 6 Total reward: 57.0 Training loss: 1.0752 Explore P: 0.9857\n",
      "Episode: 7 Total reward: 20.0 Training loss: 0.9813 Explore P: 0.9837\n",
      "Episode: 8 Total reward: 34.0 Training loss: 1.1410 Explore P: 0.9804\n",
      "Episode: 9 Total reward: 21.0 Training loss: 1.1803 Explore P: 0.9784\n",
      "Episode: 10 Total reward: 28.0 Training loss: 1.1905 Explore P: 0.9757\n",
      "Episode: 11 Total reward: 18.0 Training loss: 1.6064 Explore P: 0.9739\n",
      "Episode: 12 Total reward: 25.0 Training loss: 1.4943 Explore P: 0.9715\n",
      "Episode: 13 Total reward: 44.0 Training loss: 1.4201 Explore P: 0.9673\n",
      "Episode: 14 Total reward: 10.0 Training loss: 1.8594 Explore P: 0.9663\n",
      "Episode: 15 Total reward: 18.0 Training loss: 1.5120 Explore P: 0.9646\n",
      "Episode: 16 Total reward: 25.0 Training loss: 1.4756 Explore P: 0.9622\n",
      "Episode: 17 Total reward: 27.0 Training loss: 1.7704 Explore P: 0.9597\n",
      "Episode: 18 Total reward: 31.0 Training loss: 1.7109 Explore P: 0.9567\n",
      "Episode: 19 Total reward: 25.0 Training loss: 2.1798 Explore P: 0.9544\n",
      "Episode: 20 Total reward: 45.0 Training loss: 2.1016 Explore P: 0.9501\n",
      "Episode: 21 Total reward: 18.0 Training loss: 2.6430 Explore P: 0.9484\n",
      "Episode: 22 Total reward: 26.0 Training loss: 5.6970 Explore P: 0.9460\n",
      "Episode: 23 Total reward: 19.0 Training loss: 2.2621 Explore P: 0.9442\n",
      "Episode: 24 Total reward: 22.0 Training loss: 4.8677 Explore P: 0.9422\n",
      "Episode: 25 Total reward: 16.0 Training loss: 2.4724 Explore P: 0.9407\n",
      "Episode: 26 Total reward: 42.0 Training loss: 3.6261 Explore P: 0.9368\n",
      "Episode: 27 Total reward: 21.0 Training loss: 3.8658 Explore P: 0.9348\n",
      "Episode: 28 Total reward: 44.0 Training loss: 2.9207 Explore P: 0.9308\n",
      "Episode: 29 Total reward: 12.0 Training loss: 7.1581 Explore P: 0.9297\n",
      "Episode: 30 Total reward: 17.0 Training loss: 8.2227 Explore P: 0.9281\n",
      "Episode: 31 Total reward: 27.0 Training loss: 9.2972 Explore P: 0.9256\n",
      "Episode: 32 Total reward: 10.0 Training loss: 10.3027 Explore P: 0.9247\n",
      "Episode: 33 Total reward: 18.0 Training loss: 4.4037 Explore P: 0.9231\n",
      "Episode: 34 Total reward: 18.0 Training loss: 4.7360 Explore P: 0.9214\n",
      "Episode: 35 Total reward: 14.0 Training loss: 10.0078 Explore P: 0.9201\n",
      "Episode: 36 Total reward: 14.0 Training loss: 4.0987 Explore P: 0.9189\n",
      "Episode: 37 Total reward: 22.0 Training loss: 11.6518 Explore P: 0.9169\n",
      "Episode: 38 Total reward: 10.0 Training loss: 5.7877 Explore P: 0.9160\n",
      "Episode: 39 Total reward: 15.0 Training loss: 13.8596 Explore P: 0.9146\n",
      "Episode: 40 Total reward: 11.0 Training loss: 12.8184 Explore P: 0.9136\n",
      "Episode: 41 Total reward: 23.0 Training loss: 5.0262 Explore P: 0.9115\n",
      "Episode: 42 Total reward: 15.0 Training loss: 4.9972 Explore P: 0.9102\n",
      "Episode: 43 Total reward: 9.0 Training loss: 16.7334 Explore P: 0.9094\n",
      "Episode: 44 Total reward: 13.0 Training loss: 15.6842 Explore P: 0.9082\n",
      "Episode: 45 Total reward: 21.0 Training loss: 47.9945 Explore P: 0.9063\n",
      "Episode: 46 Total reward: 14.0 Training loss: 11.8041 Explore P: 0.9051\n",
      "Episode: 47 Total reward: 38.0 Training loss: 6.7841 Explore P: 0.9017\n",
      "Episode: 48 Total reward: 16.0 Training loss: 29.5032 Explore P: 0.9003\n",
      "Episode: 49 Total reward: 23.0 Training loss: 18.4760 Explore P: 0.8982\n",
      "Episode: 50 Total reward: 9.0 Training loss: 22.8110 Explore P: 0.8974\n",
      "Episode: 51 Total reward: 31.0 Training loss: 24.0301 Explore P: 0.8947\n",
      "Episode: 52 Total reward: 11.0 Training loss: 31.4087 Explore P: 0.8937\n",
      "Episode: 53 Total reward: 16.0 Training loss: 15.6305 Explore P: 0.8923\n",
      "Episode: 54 Total reward: 15.0 Training loss: 9.4386 Explore P: 0.8910\n",
      "Episode: 55 Total reward: 13.0 Training loss: 30.9339 Explore P: 0.8898\n",
      "Episode: 56 Total reward: 27.0 Training loss: 49.0432 Explore P: 0.8874\n",
      "Episode: 57 Total reward: 20.0 Training loss: 57.4000 Explore P: 0.8857\n",
      "Episode: 58 Total reward: 11.0 Training loss: 6.4147 Explore P: 0.8847\n",
      "Episode: 59 Total reward: 10.0 Training loss: 50.3015 Explore P: 0.8838\n",
      "Episode: 60 Total reward: 23.0 Training loss: 11.8919 Explore P: 0.8818\n",
      "Episode: 61 Total reward: 10.0 Training loss: 125.1601 Explore P: 0.8810\n",
      "Episode: 62 Total reward: 14.0 Training loss: 77.4319 Explore P: 0.8797\n",
      "Episode: 63 Total reward: 12.0 Training loss: 39.0977 Explore P: 0.8787\n",
      "Episode: 64 Total reward: 14.0 Training loss: 39.3112 Explore P: 0.8775\n",
      "Episode: 65 Total reward: 16.0 Training loss: 8.9507 Explore P: 0.8761\n",
      "Episode: 66 Total reward: 10.0 Training loss: 179.8651 Explore P: 0.8752\n",
      "Episode: 67 Total reward: 10.0 Training loss: 12.7431 Explore P: 0.8744\n",
      "Episode: 68 Total reward: 14.0 Training loss: 64.3001 Explore P: 0.8732\n",
      "Episode: 69 Total reward: 23.0 Training loss: 158.9002 Explore P: 0.8712\n",
      "Episode: 70 Total reward: 32.0 Training loss: 24.1349 Explore P: 0.8684\n",
      "Episode: 71 Total reward: 31.0 Training loss: 96.1491 Explore P: 0.8658\n",
      "Episode: 72 Total reward: 9.0 Training loss: 346.7377 Explore P: 0.8650\n",
      "Episode: 73 Total reward: 20.0 Training loss: 17.3397 Explore P: 0.8633\n",
      "Episode: 74 Total reward: 9.0 Training loss: 41.4150 Explore P: 0.8625\n",
      "Episode: 75 Total reward: 19.0 Training loss: 14.9372 Explore P: 0.8609\n",
      "Episode: 76 Total reward: 12.0 Training loss: 76.9186 Explore P: 0.8599\n",
      "Episode: 77 Total reward: 17.0 Training loss: 15.5350 Explore P: 0.8584\n",
      "Episode: 78 Total reward: 28.0 Training loss: 16.9277 Explore P: 0.8561\n",
      "Episode: 79 Total reward: 15.0 Training loss: 234.4371 Explore P: 0.8548\n",
      "Episode: 80 Total reward: 13.0 Training loss: 100.0000 Explore P: 0.8537\n",
      "Episode: 81 Total reward: 9.0 Training loss: 160.1246 Explore P: 0.8529\n",
      "Episode: 82 Total reward: 15.0 Training loss: 17.9920 Explore P: 0.8517\n",
      "Episode: 83 Total reward: 12.0 Training loss: 56.4173 Explore P: 0.8507\n",
      "Episode: 84 Total reward: 21.0 Training loss: 14.5664 Explore P: 0.8489\n",
      "Episode: 85 Total reward: 21.0 Training loss: 268.4764 Explore P: 0.8472\n",
      "Episode: 86 Total reward: 8.0 Training loss: 440.6845 Explore P: 0.8465\n",
      "Episode: 87 Total reward: 25.0 Training loss: 19.5598 Explore P: 0.8444\n",
      "Episode: 88 Total reward: 19.0 Training loss: 132.6102 Explore P: 0.8428\n",
      "Episode: 89 Total reward: 15.0 Training loss: 119.1532 Explore P: 0.8416\n",
      "Episode: 90 Total reward: 15.0 Training loss: 24.7739 Explore P: 0.8403\n",
      "Episode: 91 Total reward: 10.0 Training loss: 115.8957 Explore P: 0.8395\n",
      "Episode: 92 Total reward: 22.0 Training loss: 131.1349 Explore P: 0.8377\n",
      "Episode: 93 Total reward: 14.0 Training loss: 200.6712 Explore P: 0.8365\n",
      "Episode: 94 Total reward: 40.0 Training loss: 148.7245 Explore P: 0.8332\n",
      "Episode: 95 Total reward: 12.0 Training loss: 30.8772 Explore P: 0.8322\n",
      "Episode: 96 Total reward: 14.0 Training loss: 384.4833 Explore P: 0.8311\n",
      "Episode: 97 Total reward: 26.0 Training loss: 106.1465 Explore P: 0.8289\n",
      "Episode: 98 Total reward: 13.0 Training loss: 15.1437 Explore P: 0.8279\n",
      "Episode: 99 Total reward: 20.0 Training loss: 119.1652 Explore P: 0.8262\n",
      "Episode: 100 Total reward: 16.0 Training loss: 220.1162 Explore P: 0.8249\n",
      "Episode: 101 Total reward: 15.0 Training loss: 17.4698 Explore P: 0.8237\n",
      "Episode: 102 Total reward: 19.0 Training loss: 70.8856 Explore P: 0.8222\n",
      "Episode: 103 Total reward: 13.0 Training loss: 108.1700 Explore P: 0.8211\n",
      "Episode: 104 Total reward: 11.0 Training loss: 9.2593 Explore P: 0.8202\n",
      "Episode: 105 Total reward: 38.0 Training loss: 280.7413 Explore P: 0.8171\n",
      "Episode: 106 Total reward: 9.0 Training loss: 106.2387 Explore P: 0.8164\n",
      "Episode: 107 Total reward: 10.0 Training loss: 117.6206 Explore P: 0.8156\n",
      "Episode: 108 Total reward: 11.0 Training loss: 89.3862 Explore P: 0.8147\n",
      "Episode: 109 Total reward: 33.0 Training loss: 17.6473 Explore P: 0.8121\n",
      "Episode: 110 Total reward: 16.0 Training loss: 196.5511 Explore P: 0.8108\n",
      "Episode: 111 Total reward: 10.0 Training loss: 218.1655 Explore P: 0.8100\n",
      "Episode: 112 Total reward: 11.0 Training loss: 111.1977 Explore P: 0.8091\n",
      "Episode: 113 Total reward: 17.0 Training loss: 70.1153 Explore P: 0.8078\n",
      "Episode: 114 Total reward: 9.0 Training loss: 158.9894 Explore P: 0.8070\n",
      "Episode: 115 Total reward: 18.0 Training loss: 251.3717 Explore P: 0.8056\n",
      "Episode: 116 Total reward: 12.0 Training loss: 161.4746 Explore P: 0.8047\n",
      "Episode: 117 Total reward: 18.0 Training loss: 13.8494 Explore P: 0.8032\n",
      "Episode: 118 Total reward: 10.0 Training loss: 16.5601 Explore P: 0.8024\n",
      "Episode: 119 Total reward: 11.0 Training loss: 69.1808 Explore P: 0.8016\n",
      "Episode: 120 Total reward: 18.0 Training loss: 14.0234 Explore P: 0.8001\n",
      "Episode: 121 Total reward: 8.0 Training loss: 167.4619 Explore P: 0.7995\n",
      "Episode: 122 Total reward: 37.0 Training loss: 247.1882 Explore P: 0.7966\n",
      "Episode: 123 Total reward: 11.0 Training loss: 12.7345 Explore P: 0.7957\n",
      "Episode: 124 Total reward: 31.0 Training loss: 196.5116 Explore P: 0.7933\n",
      "Episode: 125 Total reward: 21.0 Training loss: 369.1933 Explore P: 0.7916\n",
      "Episode: 126 Total reward: 18.0 Training loss: 137.6399 Explore P: 0.7902\n",
      "Episode: 127 Total reward: 16.0 Training loss: 168.3848 Explore P: 0.7890\n",
      "Episode: 128 Total reward: 20.0 Training loss: 193.5021 Explore P: 0.7874\n",
      "Episode: 129 Total reward: 26.0 Training loss: 6.8231 Explore P: 0.7854\n",
      "Episode: 130 Total reward: 25.0 Training loss: 112.7722 Explore P: 0.7835\n",
      "Episode: 131 Total reward: 13.0 Training loss: 89.4851 Explore P: 0.7825\n",
      "Episode: 132 Total reward: 22.0 Training loss: 101.9252 Explore P: 0.7808\n",
      "Episode: 133 Total reward: 9.0 Training loss: 183.4694 Explore P: 0.7801\n",
      "Episode: 134 Total reward: 22.0 Training loss: 15.7781 Explore P: 0.7784\n",
      "Episode: 135 Total reward: 14.0 Training loss: 256.7409 Explore P: 0.7773\n",
      "Episode: 136 Total reward: 10.0 Training loss: 379.1890 Explore P: 0.7766\n",
      "Episode: 137 Total reward: 11.0 Training loss: 226.3096 Explore P: 0.7757\n",
      "Episode: 138 Total reward: 16.0 Training loss: 95.3151 Explore P: 0.7745\n",
      "Episode: 139 Total reward: 24.0 Training loss: 160.2963 Explore P: 0.7727\n",
      "Episode: 140 Total reward: 12.0 Training loss: 8.6180 Explore P: 0.7717\n",
      "Episode: 141 Total reward: 17.0 Training loss: 9.4639 Explore P: 0.7704\n",
      "Episode: 142 Total reward: 8.0 Training loss: 185.8990 Explore P: 0.7698\n",
      "Episode: 143 Total reward: 11.0 Training loss: 241.3229 Explore P: 0.7690\n",
      "Episode: 144 Total reward: 13.0 Training loss: 4.5245 Explore P: 0.7680\n",
      "Episode: 145 Total reward: 18.0 Training loss: 6.9019 Explore P: 0.7667\n",
      "Episode: 146 Total reward: 14.0 Training loss: 129.4915 Explore P: 0.7656\n",
      "Episode: 147 Total reward: 35.0 Training loss: 5.6647 Explore P: 0.7630\n",
      "Episode: 148 Total reward: 18.0 Training loss: 7.2654 Explore P: 0.7616\n",
      "Episode: 149 Total reward: 14.0 Training loss: 103.5513 Explore P: 0.7605\n",
      "Episode: 150 Total reward: 14.0 Training loss: 97.6735 Explore P: 0.7595\n",
      "Episode: 151 Total reward: 10.0 Training loss: 83.8312 Explore P: 0.7587\n",
      "Episode: 152 Total reward: 10.0 Training loss: 7.3762 Explore P: 0.7580\n",
      "Episode: 153 Total reward: 20.0 Training loss: 204.4957 Explore P: 0.7565\n",
      "Episode: 154 Total reward: 10.0 Training loss: 88.6048 Explore P: 0.7558\n",
      "Episode: 155 Total reward: 9.0 Training loss: 98.4835 Explore P: 0.7551\n",
      "Episode: 156 Total reward: 22.0 Training loss: 358.8985 Explore P: 0.7535\n",
      "Episode: 157 Total reward: 25.0 Training loss: 122.6363 Explore P: 0.7516\n",
      "Episode: 158 Total reward: 10.0 Training loss: 204.0642 Explore P: 0.7509\n",
      "Episode: 159 Total reward: 13.0 Training loss: 8.2397 Explore P: 0.7499\n",
      "Episode: 160 Total reward: 12.0 Training loss: 93.1929 Explore P: 0.7490\n",
      "Episode: 161 Total reward: 8.0 Training loss: 189.8982 Explore P: 0.7484\n",
      "Episode: 162 Total reward: 14.0 Training loss: 263.4036 Explore P: 0.7474\n",
      "Episode: 163 Total reward: 20.0 Training loss: 394.0236 Explore P: 0.7459\n",
      "Episode: 164 Total reward: 10.0 Training loss: 6.9451 Explore P: 0.7452\n",
      "Episode: 165 Total reward: 11.0 Training loss: 150.7444 Explore P: 0.7444\n",
      "Episode: 166 Total reward: 13.0 Training loss: 4.3495 Explore P: 0.7434\n",
      "Episode: 167 Total reward: 7.0 Training loss: 80.8999 Explore P: 0.7429\n",
      "Episode: 168 Total reward: 14.0 Training loss: 265.6920 Explore P: 0.7419\n",
      "Episode: 169 Total reward: 10.0 Training loss: 168.6302 Explore P: 0.7411\n",
      "Episode: 170 Total reward: 17.0 Training loss: 7.8284 Explore P: 0.7399\n",
      "Episode: 171 Total reward: 10.0 Training loss: 7.4317 Explore P: 0.7392\n",
      "Episode: 172 Total reward: 10.0 Training loss: 6.2296 Explore P: 0.7384\n",
      "Episode: 173 Total reward: 9.0 Training loss: 105.8931 Explore P: 0.7378\n",
      "Episode: 174 Total reward: 9.0 Training loss: 100.7815 Explore P: 0.7371\n",
      "Episode: 175 Total reward: 31.0 Training loss: 279.3755 Explore P: 0.7349\n",
      "Episode: 176 Total reward: 10.0 Training loss: 103.2691 Explore P: 0.7342\n",
      "Episode: 177 Total reward: 9.0 Training loss: 226.1663 Explore P: 0.7335\n",
      "Episode: 178 Total reward: 29.0 Training loss: 176.9244 Explore P: 0.7314\n",
      "Episode: 179 Total reward: 15.0 Training loss: 166.4464 Explore P: 0.7303\n",
      "Episode: 180 Total reward: 15.0 Training loss: 6.5992 Explore P: 0.7292\n",
      "Episode: 181 Total reward: 9.0 Training loss: 86.3506 Explore P: 0.7286\n",
      "Episode: 182 Total reward: 14.0 Training loss: 190.1759 Explore P: 0.7276\n",
      "Episode: 183 Total reward: 12.0 Training loss: 72.9835 Explore P: 0.7267\n",
      "Episode: 184 Total reward: 12.0 Training loss: 84.2191 Explore P: 0.7259\n",
      "Episode: 185 Total reward: 16.0 Training loss: 174.5644 Explore P: 0.7247\n",
      "Episode: 186 Total reward: 14.0 Training loss: 4.3405 Explore P: 0.7237\n",
      "Episode: 187 Total reward: 15.0 Training loss: 4.2400 Explore P: 0.7227\n",
      "Episode: 188 Total reward: 14.0 Training loss: 83.6286 Explore P: 0.7217\n",
      "Episode: 189 Total reward: 15.0 Training loss: 78.8088 Explore P: 0.7206\n",
      "Episode: 190 Total reward: 9.0 Training loss: 75.6134 Explore P: 0.7200\n",
      "Episode: 191 Total reward: 34.0 Training loss: 96.6893 Explore P: 0.7175\n",
      "Episode: 192 Total reward: 21.0 Training loss: 115.4887 Explore P: 0.7161\n",
      "Episode: 193 Total reward: 9.0 Training loss: 73.4186 Explore P: 0.7154\n",
      "Episode: 194 Total reward: 12.0 Training loss: 75.2523 Explore P: 0.7146\n",
      "Episode: 195 Total reward: 11.0 Training loss: 129.9899 Explore P: 0.7138\n",
      "Episode: 196 Total reward: 12.0 Training loss: 75.9534 Explore P: 0.7130\n",
      "Episode: 197 Total reward: 11.0 Training loss: 75.8609 Explore P: 0.7122\n",
      "Episode: 198 Total reward: 11.0 Training loss: 69.3503 Explore P: 0.7114\n",
      "Episode: 199 Total reward: 8.0 Training loss: 66.9708 Explore P: 0.7109\n",
      "Episode: 200 Total reward: 8.0 Training loss: 79.7719 Explore P: 0.7103\n",
      "Episode: 201 Total reward: 15.0 Training loss: 1.5377 Explore P: 0.7092\n",
      "Episode: 202 Total reward: 14.0 Training loss: 100.4302 Explore P: 0.7083\n",
      "Episode: 203 Total reward: 12.0 Training loss: 401.4821 Explore P: 0.7074\n",
      "Episode: 204 Total reward: 10.0 Training loss: 3.0117 Explore P: 0.7067\n",
      "Episode: 205 Total reward: 16.0 Training loss: 3.7796 Explore P: 0.7056\n",
      "Episode: 206 Total reward: 12.0 Training loss: 69.7990 Explore P: 0.7048\n",
      "Episode: 207 Total reward: 12.0 Training loss: 3.3791 Explore P: 0.7040\n",
      "Episode: 208 Total reward: 22.0 Training loss: 62.7656 Explore P: 0.7024\n",
      "Episode: 209 Total reward: 8.0 Training loss: 80.7627 Explore P: 0.7019\n",
      "Episode: 210 Total reward: 7.0 Training loss: 60.6582 Explore P: 0.7014\n",
      "Episode: 211 Total reward: 9.0 Training loss: 4.9547 Explore P: 0.7008\n",
      "Episode: 212 Total reward: 18.0 Training loss: 3.1680 Explore P: 0.6995\n",
      "Episode: 213 Total reward: 11.0 Training loss: 2.6835 Explore P: 0.6988\n",
      "Episode: 214 Total reward: 9.0 Training loss: 2.8842 Explore P: 0.6981\n",
      "Episode: 215 Total reward: 12.0 Training loss: 168.8760 Explore P: 0.6973\n",
      "Episode: 216 Total reward: 12.0 Training loss: 71.2716 Explore P: 0.6965\n",
      "Episode: 217 Total reward: 19.0 Training loss: 173.9133 Explore P: 0.6952\n",
      "Episode: 218 Total reward: 11.0 Training loss: 4.0463 Explore P: 0.6944\n",
      "Episode: 219 Total reward: 13.0 Training loss: 97.9799 Explore P: 0.6936\n",
      "Episode: 220 Total reward: 16.0 Training loss: 99.5617 Explore P: 0.6925\n",
      "Episode: 221 Total reward: 28.0 Training loss: 4.4027 Explore P: 0.6906\n",
      "Episode: 222 Total reward: 16.0 Training loss: 134.1112 Explore P: 0.6895\n",
      "Episode: 223 Total reward: 21.0 Training loss: 46.5601 Explore P: 0.6880\n",
      "Episode: 224 Total reward: 11.0 Training loss: 47.1881 Explore P: 0.6873\n",
      "Episode: 225 Total reward: 17.0 Training loss: 43.2348 Explore P: 0.6861\n",
      "Episode: 226 Total reward: 33.0 Training loss: 86.3548 Explore P: 0.6839\n",
      "Episode: 227 Total reward: 11.0 Training loss: 109.4878 Explore P: 0.6832\n",
      "Episode: 228 Total reward: 45.0 Training loss: 142.7209 Explore P: 0.6802\n",
      "Episode: 229 Total reward: 12.0 Training loss: 155.3703 Explore P: 0.6793\n",
      "Episode: 230 Total reward: 14.0 Training loss: 52.6502 Explore P: 0.6784\n",
      "Episode: 231 Total reward: 20.0 Training loss: 124.5038 Explore P: 0.6771\n",
      "Episode: 232 Total reward: 9.0 Training loss: 47.3936 Explore P: 0.6765\n",
      "Episode: 233 Total reward: 12.0 Training loss: 42.7532 Explore P: 0.6757\n",
      "Episode: 234 Total reward: 11.0 Training loss: 107.3853 Explore P: 0.6749\n",
      "Episode: 235 Total reward: 19.0 Training loss: 109.9696 Explore P: 0.6737\n",
      "Episode: 236 Total reward: 17.0 Training loss: 115.5230 Explore P: 0.6726\n",
      "Episode: 237 Total reward: 40.0 Training loss: 3.1207 Explore P: 0.6699\n",
      "Episode: 238 Total reward: 13.0 Training loss: 4.5602 Explore P: 0.6691\n",
      "Episode: 239 Total reward: 13.0 Training loss: 39.7816 Explore P: 0.6682\n",
      "Episode: 240 Total reward: 10.0 Training loss: 165.1274 Explore P: 0.6675\n",
      "Episode: 241 Total reward: 13.0 Training loss: 38.6048 Explore P: 0.6667\n",
      "Episode: 242 Total reward: 20.0 Training loss: 5.1528 Explore P: 0.6654\n",
      "Episode: 243 Total reward: 24.0 Training loss: 37.6101 Explore P: 0.6638\n",
      "Episode: 244 Total reward: 10.0 Training loss: 39.3443 Explore P: 0.6631\n",
      "Episode: 245 Total reward: 24.0 Training loss: 37.8307 Explore P: 0.6616\n",
      "Episode: 246 Total reward: 13.0 Training loss: 4.3404 Explore P: 0.6607\n",
      "Episode: 247 Total reward: 13.0 Training loss: 3.2005 Explore P: 0.6599\n",
      "Episode: 248 Total reward: 15.0 Training loss: 2.9072 Explore P: 0.6589\n",
      "Episode: 249 Total reward: 8.0 Training loss: 120.1709 Explore P: 0.6584\n",
      "Episode: 250 Total reward: 23.0 Training loss: 5.5851 Explore P: 0.6569\n",
      "Episode: 251 Total reward: 13.0 Training loss: 205.1763 Explore P: 0.6561\n",
      "Episode: 252 Total reward: 17.0 Training loss: 40.7561 Explore P: 0.6550\n",
      "Episode: 253 Total reward: 9.0 Training loss: 178.4485 Explore P: 0.6544\n",
      "Episode: 254 Total reward: 9.0 Training loss: 5.2227 Explore P: 0.6538\n",
      "Episode: 255 Total reward: 12.0 Training loss: 4.3085 Explore P: 0.6530\n",
      "Episode: 256 Total reward: 60.0 Training loss: 34.5686 Explore P: 0.6492\n",
      "Episode: 257 Total reward: 13.0 Training loss: 81.9671 Explore P: 0.6484\n",
      "Episode: 258 Total reward: 12.0 Training loss: 77.9925 Explore P: 0.6476\n",
      "Episode: 259 Total reward: 24.0 Training loss: 4.1367 Explore P: 0.6461\n",
      "Episode: 260 Total reward: 23.0 Training loss: 4.2353 Explore P: 0.6446\n",
      "Episode: 261 Total reward: 18.0 Training loss: 31.4102 Explore P: 0.6435\n",
      "Episode: 262 Total reward: 28.0 Training loss: 3.1461 Explore P: 0.6417\n",
      "Episode: 263 Total reward: 15.0 Training loss: 43.6150 Explore P: 0.6407\n",
      "Episode: 264 Total reward: 11.0 Training loss: 4.8614 Explore P: 0.6401\n",
      "Episode: 265 Total reward: 8.0 Training loss: 3.9242 Explore P: 0.6395\n",
      "Episode: 266 Total reward: 15.0 Training loss: 176.3662 Explore P: 0.6386\n",
      "Episode: 267 Total reward: 16.0 Training loss: 81.1039 Explore P: 0.6376\n",
      "Episode: 268 Total reward: 16.0 Training loss: 163.2914 Explore P: 0.6366\n",
      "Episode: 269 Total reward: 38.0 Training loss: 73.5084 Explore P: 0.6342\n",
      "Episode: 270 Total reward: 20.0 Training loss: 93.3133 Explore P: 0.6330\n",
      "Episode: 271 Total reward: 15.0 Training loss: 37.7513 Explore P: 0.6320\n",
      "Episode: 272 Total reward: 23.0 Training loss: 4.2095 Explore P: 0.6306\n",
      "Episode: 273 Total reward: 21.0 Training loss: 29.8422 Explore P: 0.6293\n",
      "Episode: 274 Total reward: 15.0 Training loss: 118.9092 Explore P: 0.6284\n",
      "Episode: 275 Total reward: 15.0 Training loss: 96.8149 Explore P: 0.6275\n",
      "Episode: 276 Total reward: 9.0 Training loss: 3.7850 Explore P: 0.6269\n",
      "Episode: 277 Total reward: 21.0 Training loss: 104.6560 Explore P: 0.6256\n",
      "Episode: 278 Total reward: 13.0 Training loss: 57.0210 Explore P: 0.6248\n",
      "Episode: 279 Total reward: 13.0 Training loss: 114.8078 Explore P: 0.6240\n",
      "Episode: 280 Total reward: 14.0 Training loss: 3.4942 Explore P: 0.6231\n",
      "Episode: 281 Total reward: 9.0 Training loss: 89.3621 Explore P: 0.6226\n",
      "Episode: 282 Total reward: 14.0 Training loss: 4.2850 Explore P: 0.6217\n",
      "Episode: 283 Total reward: 10.0 Training loss: 57.5673 Explore P: 0.6211\n",
      "Episode: 284 Total reward: 18.0 Training loss: 5.3351 Explore P: 0.6200\n",
      "Episode: 285 Total reward: 13.0 Training loss: 81.8222 Explore P: 0.6192\n",
      "Episode: 286 Total reward: 43.0 Training loss: 3.6404 Explore P: 0.6166\n",
      "Episode: 287 Total reward: 10.0 Training loss: 118.2980 Explore P: 0.6160\n",
      "Episode: 288 Total reward: 14.0 Training loss: 33.8811 Explore P: 0.6152\n",
      "Episode: 289 Total reward: 24.0 Training loss: 157.9323 Explore P: 0.6137\n",
      "Episode: 290 Total reward: 26.0 Training loss: 5.6219 Explore P: 0.6121\n",
      "Episode: 291 Total reward: 27.0 Training loss: 3.5775 Explore P: 0.6105\n",
      "Episode: 292 Total reward: 15.0 Training loss: 3.7424 Explore P: 0.6096\n",
      "Episode: 293 Total reward: 19.0 Training loss: 61.6045 Explore P: 0.6085\n",
      "Episode: 294 Total reward: 15.0 Training loss: 27.3274 Explore P: 0.6076\n",
      "Episode: 295 Total reward: 13.0 Training loss: 65.1066 Explore P: 0.6068\n",
      "Episode: 296 Total reward: 17.0 Training loss: 96.4039 Explore P: 0.6058\n",
      "Episode: 297 Total reward: 10.0 Training loss: 2.4543 Explore P: 0.6052\n",
      "Episode: 298 Total reward: 12.0 Training loss: 2.5519 Explore P: 0.6045\n",
      "Episode: 299 Total reward: 13.0 Training loss: 2.5767 Explore P: 0.6037\n",
      "Episode: 300 Total reward: 11.0 Training loss: 75.0181 Explore P: 0.6031\n",
      "Episode: 301 Total reward: 17.0 Training loss: 4.4149 Explore P: 0.6021\n",
      "Episode: 302 Total reward: 9.0 Training loss: 232.0412 Explore P: 0.6015\n",
      "Episode: 303 Total reward: 12.0 Training loss: 2.6926 Explore P: 0.6008\n",
      "Episode: 304 Total reward: 11.0 Training loss: 2.8646 Explore P: 0.6002\n",
      "Episode: 305 Total reward: 15.0 Training loss: 64.3614 Explore P: 0.5993\n",
      "Episode: 306 Total reward: 15.0 Training loss: 132.5479 Explore P: 0.5984\n",
      "Episode: 307 Total reward: 15.0 Training loss: 2.7668 Explore P: 0.5975\n",
      "Episode: 308 Total reward: 9.0 Training loss: 2.5443 Explore P: 0.5970\n",
      "Episode: 309 Total reward: 12.0 Training loss: 28.7469 Explore P: 0.5963\n",
      "Episode: 310 Total reward: 15.0 Training loss: 28.6545 Explore P: 0.5954\n",
      "Episode: 311 Total reward: 11.0 Training loss: 2.9092 Explore P: 0.5948\n",
      "Episode: 312 Total reward: 17.0 Training loss: 60.6472 Explore P: 0.5938\n",
      "Episode: 313 Total reward: 36.0 Training loss: 32.4013 Explore P: 0.5917\n",
      "Episode: 314 Total reward: 14.0 Training loss: 97.1553 Explore P: 0.5909\n",
      "Episode: 315 Total reward: 8.0 Training loss: 46.8328 Explore P: 0.5904\n",
      "Episode: 316 Total reward: 15.0 Training loss: 2.1711 Explore P: 0.5895\n",
      "Episode: 317 Total reward: 14.0 Training loss: 65.0311 Explore P: 0.5887\n",
      "Episode: 318 Total reward: 9.0 Training loss: 1.5711 Explore P: 0.5882\n",
      "Episode: 319 Total reward: 20.0 Training loss: 34.9642 Explore P: 0.5870\n",
      "Episode: 320 Total reward: 10.0 Training loss: 47.5667 Explore P: 0.5865\n",
      "Episode: 321 Total reward: 11.0 Training loss: 1.6267 Explore P: 0.5858\n",
      "Episode: 322 Total reward: 18.0 Training loss: 2.2109 Explore P: 0.5848\n",
      "Episode: 323 Total reward: 10.0 Training loss: 1.1409 Explore P: 0.5842\n",
      "Episode: 324 Total reward: 36.0 Training loss: 97.5349 Explore P: 0.5822\n",
      "Episode: 325 Total reward: 8.0 Training loss: 44.9460 Explore P: 0.5817\n",
      "Episode: 326 Total reward: 8.0 Training loss: 1.9871 Explore P: 0.5812\n",
      "Episode: 327 Total reward: 10.0 Training loss: 44.0349 Explore P: 0.5807\n",
      "Episode: 328 Total reward: 17.0 Training loss: 77.5336 Explore P: 0.5797\n",
      "Episode: 329 Total reward: 10.0 Training loss: 24.6135 Explore P: 0.5791\n",
      "Episode: 330 Total reward: 13.0 Training loss: 81.9888 Explore P: 0.5784\n",
      "Episode: 331 Total reward: 11.0 Training loss: 1.1141 Explore P: 0.5778\n",
      "Episode: 332 Total reward: 12.0 Training loss: 64.9433 Explore P: 0.5771\n",
      "Episode: 333 Total reward: 29.0 Training loss: 54.8631 Explore P: 0.5754\n",
      "Episode: 334 Total reward: 7.0 Training loss: 116.4124 Explore P: 0.5750\n",
      "Episode: 335 Total reward: 23.0 Training loss: 75.2138 Explore P: 0.5737\n",
      "Episode: 336 Total reward: 12.0 Training loss: 95.1553 Explore P: 0.5731\n",
      "Episode: 337 Total reward: 19.0 Training loss: 45.3669 Explore P: 0.5720\n",
      "Episode: 338 Total reward: 8.0 Training loss: 1.4226 Explore P: 0.5716\n",
      "Episode: 339 Total reward: 28.0 Training loss: 32.1537 Explore P: 0.5700\n",
      "Episode: 340 Total reward: 11.0 Training loss: 25.2549 Explore P: 0.5694\n",
      "Episode: 341 Total reward: 10.0 Training loss: 85.5473 Explore P: 0.5688\n",
      "Episode: 342 Total reward: 11.0 Training loss: 25.7576 Explore P: 0.5682\n",
      "Episode: 343 Total reward: 12.0 Training loss: 61.5176 Explore P: 0.5675\n",
      "Episode: 344 Total reward: 9.0 Training loss: 30.2835 Explore P: 0.5670\n",
      "Episode: 345 Total reward: 33.0 Training loss: 64.3906 Explore P: 0.5652\n",
      "Episode: 346 Total reward: 11.0 Training loss: 59.3890 Explore P: 0.5646\n",
      "Episode: 347 Total reward: 8.0 Training loss: 1.0407 Explore P: 0.5641\n",
      "Episode: 348 Total reward: 18.0 Training loss: 22.8522 Explore P: 0.5631\n",
      "Episode: 349 Total reward: 35.0 Training loss: 0.9511 Explore P: 0.5612\n",
      "Episode: 350 Total reward: 13.0 Training loss: 80.7314 Explore P: 0.5605\n",
      "Episode: 351 Total reward: 13.0 Training loss: 0.8648 Explore P: 0.5598\n",
      "Episode: 352 Total reward: 8.0 Training loss: 74.5825 Explore P: 0.5593\n",
      "Episode: 353 Total reward: 14.0 Training loss: 1.4689 Explore P: 0.5586\n",
      "Episode: 354 Total reward: 23.0 Training loss: 28.2867 Explore P: 0.5573\n",
      "Episode: 355 Total reward: 10.0 Training loss: 27.6840 Explore P: 0.5568\n",
      "Episode: 356 Total reward: 17.0 Training loss: 26.9938 Explore P: 0.5558\n",
      "Episode: 357 Total reward: 12.0 Training loss: 1.4154 Explore P: 0.5552\n",
      "Episode: 358 Total reward: 24.0 Training loss: 55.2959 Explore P: 0.5539\n",
      "Episode: 359 Total reward: 28.0 Training loss: 60.4271 Explore P: 0.5523\n",
      "Episode: 360 Total reward: 20.0 Training loss: 41.9222 Explore P: 0.5513\n",
      "Episode: 361 Total reward: 17.0 Training loss: 1.7490 Explore P: 0.5503\n",
      "Episode: 362 Total reward: 11.0 Training loss: 47.0155 Explore P: 0.5497\n",
      "Episode: 363 Total reward: 22.0 Training loss: 1.1755 Explore P: 0.5486\n",
      "Episode: 364 Total reward: 37.0 Training loss: 25.7158 Explore P: 0.5466\n",
      "Episode: 365 Total reward: 27.0 Training loss: 21.7243 Explore P: 0.5451\n",
      "Episode: 366 Total reward: 22.0 Training loss: 40.6038 Explore P: 0.5440\n",
      "Episode: 367 Total reward: 29.0 Training loss: 0.8826 Explore P: 0.5424\n",
      "Episode: 368 Total reward: 28.0 Training loss: 21.6052 Explore P: 0.5409\n",
      "Episode: 369 Total reward: 33.0 Training loss: 21.1396 Explore P: 0.5392\n",
      "Episode: 370 Total reward: 41.0 Training loss: 16.6171 Explore P: 0.5370\n",
      "Episode: 371 Total reward: 52.0 Training loss: 19.2292 Explore P: 0.5343\n",
      "Episode: 372 Total reward: 71.0 Training loss: 0.7866 Explore P: 0.5306\n",
      "Episode: 373 Total reward: 47.0 Training loss: 21.6438 Explore P: 0.5281\n",
      "Episode: 374 Total reward: 13.0 Training loss: 0.8285 Explore P: 0.5274\n",
      "Episode: 375 Total reward: 56.0 Training loss: 1.0852 Explore P: 0.5246\n",
      "Episode: 376 Total reward: 29.0 Training loss: 1.1420 Explore P: 0.5231\n",
      "Episode: 377 Total reward: 20.0 Training loss: 24.4531 Explore P: 0.5220\n",
      "Episode: 378 Total reward: 69.0 Training loss: 20.1822 Explore P: 0.5185\n",
      "Episode: 379 Total reward: 47.0 Training loss: 30.2008 Explore P: 0.5161\n",
      "Episode: 380 Total reward: 20.0 Training loss: 0.8657 Explore P: 0.5151\n",
      "Episode: 381 Total reward: 48.0 Training loss: 28.1722 Explore P: 0.5127\n",
      "Episode: 382 Total reward: 40.0 Training loss: 28.3759 Explore P: 0.5107\n",
      "Episode: 383 Total reward: 79.0 Training loss: 1.1394 Explore P: 0.5068\n",
      "Episode: 384 Total reward: 17.0 Training loss: 1.1625 Explore P: 0.5059\n",
      "Episode: 385 Total reward: 47.0 Training loss: 31.1255 Explore P: 0.5036\n",
      "Episode: 386 Total reward: 41.0 Training loss: 1.0497 Explore P: 0.5016\n",
      "Episode: 387 Total reward: 35.0 Training loss: 27.9515 Explore P: 0.4999\n",
      "Episode: 388 Total reward: 15.0 Training loss: 37.3475 Explore P: 0.4991\n",
      "Episode: 389 Total reward: 92.0 Training loss: 0.5950 Explore P: 0.4946\n",
      "Episode: 390 Total reward: 51.0 Training loss: 11.9298 Explore P: 0.4922\n",
      "Episode: 391 Total reward: 40.0 Training loss: 44.5893 Explore P: 0.4902\n",
      "Episode: 392 Total reward: 42.0 Training loss: 1.3690 Explore P: 0.4882\n",
      "Episode: 393 Total reward: 33.0 Training loss: 1.5740 Explore P: 0.4867\n",
      "Episode: 394 Total reward: 59.0 Training loss: 15.3525 Explore P: 0.4839\n",
      "Episode: 395 Total reward: 46.0 Training loss: 1.4098 Explore P: 0.4817\n",
      "Episode: 396 Total reward: 27.0 Training loss: 23.0567 Explore P: 0.4804\n",
      "Episode: 397 Total reward: 62.0 Training loss: 16.7311 Explore P: 0.4775\n",
      "Episode: 398 Total reward: 36.0 Training loss: 0.8065 Explore P: 0.4758\n",
      "Episode: 399 Total reward: 29.0 Training loss: 8.6395 Explore P: 0.4745\n",
      "Episode: 400 Total reward: 40.0 Training loss: 29.2368 Explore P: 0.4726\n",
      "Episode: 401 Total reward: 69.0 Training loss: 35.7757 Explore P: 0.4694\n",
      "Episode: 402 Total reward: 51.0 Training loss: 19.1553 Explore P: 0.4671\n",
      "Episode: 403 Total reward: 45.0 Training loss: 32.2039 Explore P: 0.4650\n",
      "Episode: 404 Total reward: 53.0 Training loss: 0.4961 Explore P: 0.4626\n",
      "Episode: 405 Total reward: 23.0 Training loss: 1.1207 Explore P: 0.4616\n",
      "Episode: 406 Total reward: 49.0 Training loss: 15.0689 Explore P: 0.4594\n",
      "Episode: 407 Total reward: 76.0 Training loss: 21.0256 Explore P: 0.4560\n",
      "Episode: 408 Total reward: 113.0 Training loss: 0.9820 Explore P: 0.4510\n",
      "Episode: 409 Total reward: 40.0 Training loss: 15.0275 Explore P: 0.4492\n",
      "Episode: 410 Total reward: 48.0 Training loss: 26.3719 Explore P: 0.4471\n",
      "Episode: 411 Total reward: 62.0 Training loss: 1.1769 Explore P: 0.4444\n",
      "Episode: 412 Total reward: 58.0 Training loss: 1.3434 Explore P: 0.4419\n",
      "Episode: 413 Total reward: 31.0 Training loss: 1.1560 Explore P: 0.4406\n",
      "Episode: 414 Total reward: 46.0 Training loss: 1.9519 Explore P: 0.4386\n",
      "Episode: 415 Total reward: 59.0 Training loss: 1.6637 Explore P: 0.4361\n",
      "Episode: 416 Total reward: 36.0 Training loss: 14.2515 Explore P: 0.4345\n",
      "Episode: 417 Total reward: 43.0 Training loss: 53.4373 Explore P: 0.4327\n",
      "Episode: 418 Total reward: 52.0 Training loss: 37.5957 Explore P: 0.4305\n",
      "Episode: 419 Total reward: 62.0 Training loss: 20.2125 Explore P: 0.4279\n",
      "Episode: 420 Total reward: 44.0 Training loss: 1.9361 Explore P: 0.4261\n",
      "Episode: 421 Total reward: 39.0 Training loss: 1.6318 Explore P: 0.4245\n",
      "Episode: 422 Total reward: 57.0 Training loss: 1.1355 Explore P: 0.4221\n",
      "Episode: 423 Total reward: 40.0 Training loss: 18.2743 Explore P: 0.4205\n",
      "Episode: 424 Total reward: 54.0 Training loss: 26.9754 Explore P: 0.4183\n",
      "Episode: 425 Total reward: 38.0 Training loss: 10.7927 Explore P: 0.4167\n",
      "Episode: 426 Total reward: 36.0 Training loss: 1.6454 Explore P: 0.4153\n",
      "Episode: 427 Total reward: 23.0 Training loss: 16.5054 Explore P: 0.4143\n",
      "Episode: 428 Total reward: 37.0 Training loss: 19.8969 Explore P: 0.4128\n",
      "Episode: 429 Total reward: 45.0 Training loss: 1.0005 Explore P: 0.4110\n",
      "Episode: 430 Total reward: 49.0 Training loss: 50.5275 Explore P: 0.4091\n",
      "Episode: 431 Total reward: 94.0 Training loss: 38.3371 Explore P: 0.4053\n",
      "Episode: 432 Total reward: 37.0 Training loss: 41.3246 Explore P: 0.4039\n",
      "Episode: 433 Total reward: 34.0 Training loss: 19.6497 Explore P: 0.4025\n",
      "Episode: 434 Total reward: 45.0 Training loss: 1.2349 Explore P: 0.4008\n",
      "Episode: 435 Total reward: 66.0 Training loss: 1.7856 Explore P: 0.3982\n",
      "Episode: 436 Total reward: 58.0 Training loss: 1.1165 Explore P: 0.3959\n",
      "Episode: 437 Total reward: 61.0 Training loss: 9.8346 Explore P: 0.3936\n",
      "Episode: 438 Total reward: 100.0 Training loss: 1.3450 Explore P: 0.3898\n",
      "Episode: 439 Total reward: 56.0 Training loss: 38.2424 Explore P: 0.3877\n",
      "Episode: 440 Total reward: 75.0 Training loss: 56.5198 Explore P: 0.3848\n",
      "Episode: 441 Total reward: 24.0 Training loss: 2.0656 Explore P: 0.3839\n",
      "Episode: 442 Total reward: 71.0 Training loss: 1.6063 Explore P: 0.3813\n",
      "Episode: 443 Total reward: 50.0 Training loss: 13.1283 Explore P: 0.3794\n",
      "Episode: 444 Total reward: 96.0 Training loss: 1.7823 Explore P: 0.3759\n",
      "Episode: 445 Total reward: 57.0 Training loss: 25.8597 Explore P: 0.3738\n",
      "Episode: 446 Total reward: 48.0 Training loss: 25.5723 Explore P: 0.3721\n",
      "Episode: 447 Total reward: 57.0 Training loss: 42.5737 Explore P: 0.3700\n",
      "Episode: 448 Total reward: 124.0 Training loss: 15.6056 Explore P: 0.3656\n",
      "Episode: 449 Total reward: 66.0 Training loss: 1.5028 Explore P: 0.3633\n",
      "Episode: 450 Total reward: 109.0 Training loss: 48.4802 Explore P: 0.3594\n",
      "Episode: 451 Total reward: 70.0 Training loss: 16.8105 Explore P: 0.3570\n",
      "Episode: 452 Total reward: 75.0 Training loss: 37.8409 Explore P: 0.3544\n",
      "Episode: 453 Total reward: 100.0 Training loss: 54.7838 Explore P: 0.3510\n",
      "Episode: 454 Total reward: 63.0 Training loss: 56.2533 Explore P: 0.3488\n",
      "Episode: 455 Total reward: 112.0 Training loss: 51.2407 Explore P: 0.3451\n",
      "Episode: 456 Total reward: 150.0 Training loss: 2.0588 Explore P: 0.3401\n",
      "Episode: 457 Total reward: 89.0 Training loss: 23.2650 Explore P: 0.3371\n",
      "Episode: 458 Total reward: 144.0 Training loss: 18.2118 Explore P: 0.3325\n",
      "Episode: 459 Total reward: 88.0 Training loss: 2.0517 Explore P: 0.3296\n",
      "Episode: 460 Total reward: 125.0 Training loss: 21.7324 Explore P: 0.3257\n",
      "Episode: 461 Total reward: 43.0 Training loss: 2.3826 Explore P: 0.3243\n",
      "Episode: 462 Total reward: 34.0 Training loss: 1.5958 Explore P: 0.3233\n",
      "Episode: 463 Total reward: 59.0 Training loss: 3.0247 Explore P: 0.3214\n",
      "Episode: 464 Total reward: 53.0 Training loss: 81.7162 Explore P: 0.3198\n",
      "Episode: 465 Total reward: 56.0 Training loss: 1.5044 Explore P: 0.3180\n",
      "Episode: 466 Total reward: 103.0 Training loss: 15.8160 Explore P: 0.3149\n",
      "Episode: 467 Total reward: 54.0 Training loss: 2.9446 Explore P: 0.3132\n",
      "Episode: 468 Total reward: 80.0 Training loss: 46.0823 Explore P: 0.3108\n",
      "Episode: 469 Total reward: 39.0 Training loss: 69.9744 Explore P: 0.3096\n",
      "Episode: 470 Total reward: 76.0 Training loss: 0.9475 Explore P: 0.3074\n",
      "Episode: 471 Total reward: 116.0 Training loss: 1.4710 Explore P: 0.3039\n",
      "Episode: 472 Total reward: 38.0 Training loss: 49.6191 Explore P: 0.3028\n",
      "Episode: 473 Total reward: 79.0 Training loss: 2.8861 Explore P: 0.3005\n",
      "Episode: 474 Total reward: 36.0 Training loss: 27.5589 Explore P: 0.2995\n",
      "Episode: 475 Total reward: 36.0 Training loss: 2.1624 Explore P: 0.2984\n",
      "Episode: 476 Total reward: 43.0 Training loss: 129.1330 Explore P: 0.2972\n",
      "Episode: 477 Total reward: 90.0 Training loss: 1.7891 Explore P: 0.2946\n",
      "Episode: 478 Total reward: 37.0 Training loss: 1.8362 Explore P: 0.2936\n",
      "Episode: 479 Total reward: 97.0 Training loss: 40.6323 Explore P: 0.2908\n",
      "Episode: 480 Total reward: 83.0 Training loss: 6.7456 Explore P: 0.2885\n",
      "Episode: 481 Total reward: 43.0 Training loss: 2.6939 Explore P: 0.2873\n",
      "Episode: 482 Total reward: 40.0 Training loss: 15.3023 Explore P: 0.2862\n",
      "Episode: 483 Total reward: 28.0 Training loss: 2.6745 Explore P: 0.2854\n",
      "Episode: 484 Total reward: 46.0 Training loss: 2.5788 Explore P: 0.2842\n",
      "Episode: 485 Total reward: 28.0 Training loss: 18.0683 Explore P: 0.2834\n",
      "Episode: 486 Total reward: 42.0 Training loss: 16.8234 Explore P: 0.2823\n",
      "Episode: 487 Total reward: 60.0 Training loss: 71.2479 Explore P: 0.2806\n",
      "Episode: 488 Total reward: 32.0 Training loss: 39.8138 Explore P: 0.2798\n",
      "Episode: 489 Total reward: 58.0 Training loss: 131.6920 Explore P: 0.2782\n",
      "Episode: 490 Total reward: 47.0 Training loss: 84.6126 Explore P: 0.2770\n",
      "Episode: 491 Total reward: 40.0 Training loss: 2.2592 Explore P: 0.2759\n",
      "Episode: 492 Total reward: 56.0 Training loss: 2.2025 Explore P: 0.2744\n",
      "Episode: 493 Total reward: 54.0 Training loss: 13.8466 Explore P: 0.2730\n",
      "Episode: 494 Total reward: 51.0 Training loss: 21.6076 Explore P: 0.2716\n",
      "Episode: 495 Total reward: 70.0 Training loss: 2.4869 Explore P: 0.2698\n",
      "Episode: 496 Total reward: 62.0 Training loss: 3.2513 Explore P: 0.2682\n",
      "Episode: 497 Total reward: 22.0 Training loss: 101.2119 Explore P: 0.2677\n",
      "Episode: 498 Total reward: 33.0 Training loss: 2.4539 Explore P: 0.2668\n",
      "Episode: 499 Total reward: 56.0 Training loss: 137.3335 Explore P: 0.2654\n",
      "Episode: 500 Total reward: 40.0 Training loss: 1.3262 Explore P: 0.2643\n",
      "Episode: 501 Total reward: 41.0 Training loss: 32.5635 Explore P: 0.2633\n",
      "Episode: 502 Total reward: 146.0 Training loss: 1.3305 Explore P: 0.2596\n",
      "Episode: 503 Total reward: 39.0 Training loss: 2.7178 Explore P: 0.2587\n",
      "Episode: 504 Total reward: 39.0 Training loss: 2.4937 Explore P: 0.2577\n",
      "Episode: 505 Total reward: 67.0 Training loss: 1.8107 Explore P: 0.2560\n",
      "Episode: 506 Total reward: 95.0 Training loss: 2.3139 Explore P: 0.2537\n",
      "Episode: 507 Total reward: 44.0 Training loss: 1.7880 Explore P: 0.2526\n",
      "Episode: 508 Total reward: 52.0 Training loss: 0.5187 Explore P: 0.2514\n",
      "Episode: 509 Total reward: 52.0 Training loss: 141.6924 Explore P: 0.2501\n",
      "Episode: 510 Total reward: 30.0 Training loss: 3.3324 Explore P: 0.2494\n",
      "Episode: 511 Total reward: 59.0 Training loss: 1.3767 Explore P: 0.2480\n",
      "Episode: 512 Total reward: 37.0 Training loss: 0.8607 Explore P: 0.2471\n",
      "Episode: 513 Total reward: 74.0 Training loss: 3.0431 Explore P: 0.2454\n",
      "Episode: 514 Total reward: 63.0 Training loss: 11.4371 Explore P: 0.2439\n",
      "Episode: 515 Total reward: 53.0 Training loss: 1.2495 Explore P: 0.2427\n",
      "Episode: 516 Total reward: 37.0 Training loss: 1.3823 Explore P: 0.2418\n",
      "Episode: 517 Total reward: 82.0 Training loss: 0.8803 Explore P: 0.2399\n",
      "Episode: 518 Total reward: 49.0 Training loss: 2.1207 Explore P: 0.2388\n",
      "Episode: 519 Total reward: 54.0 Training loss: 100.8731 Explore P: 0.2376\n",
      "Episode: 520 Total reward: 43.0 Training loss: 1.2997 Explore P: 0.2366\n",
      "Episode: 521 Total reward: 38.0 Training loss: 88.5672 Explore P: 0.2357\n",
      "Episode: 522 Total reward: 44.0 Training loss: 2.8539 Explore P: 0.2347\n",
      "Episode: 523 Total reward: 67.0 Training loss: 1.4142 Explore P: 0.2332\n",
      "Episode: 524 Total reward: 50.0 Training loss: 0.9756 Explore P: 0.2321\n",
      "Episode: 525 Total reward: 58.0 Training loss: 73.8353 Explore P: 0.2308\n",
      "Episode: 526 Total reward: 40.0 Training loss: 32.8842 Explore P: 0.2300\n",
      "Episode: 527 Total reward: 56.0 Training loss: 21.9559 Explore P: 0.2287\n",
      "Episode: 528 Total reward: 51.0 Training loss: 54.3631 Explore P: 0.2276\n",
      "Episode: 529 Total reward: 199.0 Training loss: 0.6774 Explore P: 0.2233\n",
      "Episode: 530 Total reward: 71.0 Training loss: 2.0073 Explore P: 0.2218\n",
      "Episode: 531 Total reward: 189.0 Training loss: 0.6431 Explore P: 0.2178\n",
      "Episode: 532 Total reward: 40.0 Training loss: 15.4829 Explore P: 0.2170\n",
      "Episode: 533 Total reward: 56.0 Training loss: 0.6943 Explore P: 0.2159\n",
      "Episode: 534 Total reward: 74.0 Training loss: 35.5394 Explore P: 0.2143\n",
      "Episode: 535 Total reward: 108.0 Training loss: 1.1566 Explore P: 0.2121\n",
      "Episode: 536 Total reward: 56.0 Training loss: 103.7612 Explore P: 0.2110\n",
      "Episode: 537 Total reward: 199.0 Training loss: 70.9232 Explore P: 0.2071\n",
      "Episode: 538 Total reward: 65.0 Training loss: 1.0080 Explore P: 0.2058\n",
      "Episode: 539 Total reward: 125.0 Training loss: 1.6141 Explore P: 0.2034\n",
      "Episode: 540 Total reward: 86.0 Training loss: 28.4409 Explore P: 0.2017\n",
      "Episode: 541 Total reward: 64.0 Training loss: 243.1117 Explore P: 0.2005\n",
      "Episode: 542 Total reward: 56.0 Training loss: 1.1750 Explore P: 0.1994\n",
      "Episode: 543 Total reward: 108.0 Training loss: 0.5014 Explore P: 0.1974\n",
      "Episode: 544 Total reward: 133.0 Training loss: 1.1702 Explore P: 0.1949\n",
      "Episode: 545 Total reward: 199.0 Training loss: 1.1645 Explore P: 0.1913\n",
      "Episode: 546 Total reward: 122.0 Training loss: 41.7692 Explore P: 0.1891\n",
      "Episode: 547 Total reward: 76.0 Training loss: 2.4396 Explore P: 0.1877\n",
      "Episode: 548 Total reward: 89.0 Training loss: 0.7034 Explore P: 0.1861\n",
      "Episode: 549 Total reward: 136.0 Training loss: 0.8590 Explore P: 0.1837\n",
      "Episode: 550 Total reward: 199.0 Training loss: 0.7594 Explore P: 0.1803\n",
      "Episode: 551 Total reward: 94.0 Training loss: 0.6958 Explore P: 0.1787\n",
      "Episode: 552 Total reward: 199.0 Training loss: 1.1986 Explore P: 0.1754\n",
      "Episode: 553 Total reward: 121.0 Training loss: 0.6312 Explore P: 0.1734\n",
      "Episode: 554 Total reward: 135.0 Training loss: 1.6408 Explore P: 0.1712\n",
      "Episode: 555 Total reward: 70.0 Training loss: 1.2204 Explore P: 0.1701\n",
      "Episode: 556 Total reward: 65.0 Training loss: 1.5909 Explore P: 0.1691\n",
      "Episode: 557 Total reward: 116.0 Training loss: 1.0275 Explore P: 0.1672\n",
      "Episode: 558 Total reward: 60.0 Training loss: 24.8210 Explore P: 0.1663\n",
      "Episode: 559 Total reward: 68.0 Training loss: 0.7936 Explore P: 0.1652\n",
      "Episode: 560 Total reward: 188.0 Training loss: 29.1110 Explore P: 0.1623\n",
      "Episode: 561 Total reward: 109.0 Training loss: 0.2874 Explore P: 0.1607\n",
      "Episode: 562 Total reward: 65.0 Training loss: 1.0616 Explore P: 0.1597\n",
      "Episode: 563 Total reward: 111.0 Training loss: 5.8382 Explore P: 0.1581\n",
      "Episode: 564 Total reward: 147.0 Training loss: 24.8873 Explore P: 0.1559\n",
      "Episode: 565 Total reward: 195.0 Training loss: 0.7557 Explore P: 0.1531\n",
      "Episode: 566 Total reward: 83.0 Training loss: 0.7740 Explore P: 0.1519\n",
      "Episode: 567 Total reward: 199.0 Training loss: 0.9659 Explore P: 0.1491\n",
      "Episode: 568 Total reward: 143.0 Training loss: 0.8830 Explore P: 0.1471\n",
      "Episode: 569 Total reward: 86.0 Training loss: 0.8293 Explore P: 0.1460\n",
      "Episode: 570 Total reward: 139.0 Training loss: 1.2764 Explore P: 0.1441\n",
      "Episode: 571 Total reward: 76.0 Training loss: 0.9366 Explore P: 0.1431\n",
      "Episode: 572 Total reward: 62.0 Training loss: 0.3759 Explore P: 0.1422\n",
      "Episode: 573 Total reward: 98.0 Training loss: 0.9584 Explore P: 0.1409\n",
      "Episode: 574 Total reward: 73.0 Training loss: 22.4917 Explore P: 0.1400\n",
      "Episode: 575 Total reward: 65.0 Training loss: 0.8753 Explore P: 0.1392\n",
      "Episode: 576 Total reward: 199.0 Training loss: 16.1185 Explore P: 0.1366\n",
      "Episode: 577 Total reward: 115.0 Training loss: 1.0758 Explore P: 0.1352\n",
      "Episode: 578 Total reward: 86.0 Training loss: 1.6961 Explore P: 0.1341\n",
      "Episode: 579 Total reward: 159.0 Training loss: 39.6422 Explore P: 0.1321\n",
      "Episode: 580 Total reward: 109.0 Training loss: 0.4571 Explore P: 0.1308\n",
      "Episode: 581 Total reward: 149.0 Training loss: 1.1675 Explore P: 0.1290\n",
      "Episode: 582 Total reward: 93.0 Training loss: 0.7797 Explore P: 0.1279\n",
      "Episode: 583 Total reward: 120.0 Training loss: 25.6078 Explore P: 0.1265\n",
      "Episode: 584 Total reward: 182.0 Training loss: 0.5338 Explore P: 0.1244\n",
      "Episode: 585 Total reward: 199.0 Training loss: 0.7388 Explore P: 0.1222\n",
      "Episode: 586 Total reward: 199.0 Training loss: 0.6702 Explore P: 0.1199\n",
      "Episode: 587 Total reward: 199.0 Training loss: 0.4911 Explore P: 0.1178\n",
      "Episode: 588 Total reward: 117.0 Training loss: 6.3313 Explore P: 0.1165\n",
      "Episode: 589 Total reward: 141.0 Training loss: 0.7053 Explore P: 0.1150\n",
      "Episode: 590 Total reward: 199.0 Training loss: 1.0621 Explore P: 0.1130\n",
      "Episode: 591 Total reward: 199.0 Training loss: 0.6526 Explore P: 0.1109\n",
      "Episode: 592 Total reward: 199.0 Training loss: 7.2378 Explore P: 0.1089\n",
      "Episode: 593 Total reward: 180.0 Training loss: 4.6168 Explore P: 0.1072\n",
      "Episode: 594 Total reward: 173.0 Training loss: 0.3226 Explore P: 0.1055\n",
      "Episode: 595 Total reward: 199.0 Training loss: 0.3136 Explore P: 0.1036\n",
      "Episode: 596 Total reward: 104.0 Training loss: 0.3114 Explore P: 0.1027\n",
      "Episode: 597 Total reward: 199.0 Training loss: 0.5119 Explore P: 0.1008\n",
      "Episode: 598 Total reward: 141.0 Training loss: 4.4395 Explore P: 0.0996\n",
      "Episode: 599 Total reward: 137.0 Training loss: 0.7449 Explore P: 0.0983\n",
      "Episode: 600 Total reward: 102.0 Training loss: 0.4457 Explore P: 0.0975\n",
      "Episode: 601 Total reward: 199.0 Training loss: 0.8140 Explore P: 0.0957\n",
      "Episode: 602 Total reward: 197.0 Training loss: 0.5266 Explore P: 0.0941\n",
      "Episode: 603 Total reward: 199.0 Training loss: 10.3620 Explore P: 0.0924\n",
      "Episode: 604 Total reward: 199.0 Training loss: 0.3926 Explore P: 0.0908\n",
      "Episode: 605 Total reward: 189.0 Training loss: 0.4722 Explore P: 0.0893\n",
      "Episode: 606 Total reward: 162.0 Training loss: 0.3710 Explore P: 0.0880\n",
      "Episode: 607 Total reward: 199.0 Training loss: 218.3104 Explore P: 0.0865\n",
      "Episode: 608 Total reward: 179.0 Training loss: 0.3257 Explore P: 0.0851\n",
      "Episode: 609 Total reward: 199.0 Training loss: 0.3500 Explore P: 0.0836\n",
      "Episode: 610 Total reward: 199.0 Training loss: 0.3512 Explore P: 0.0822\n",
      "Episode: 611 Total reward: 133.0 Training loss: 0.3425 Explore P: 0.0812\n",
      "Episode: 612 Total reward: 186.0 Training loss: 0.3545 Explore P: 0.0799\n",
      "Episode: 613 Total reward: 199.0 Training loss: 0.2566 Explore P: 0.0785\n",
      "Episode: 614 Total reward: 199.0 Training loss: 0.7037 Explore P: 0.0772\n",
      "Episode: 615 Total reward: 80.0 Training loss: 0.4218 Explore P: 0.0766\n",
      "Episode: 616 Total reward: 122.0 Training loss: 0.4104 Explore P: 0.0758\n",
      "Episode: 617 Total reward: 199.0 Training loss: 0.6226 Explore P: 0.0745\n",
      "Episode: 618 Total reward: 86.0 Training loss: 0.4501 Explore P: 0.0740\n",
      "Episode: 619 Total reward: 87.0 Training loss: 0.2723 Explore P: 0.0734\n",
      "Episode: 620 Total reward: 199.0 Training loss: 0.5485 Explore P: 0.0722\n",
      "Episode: 621 Total reward: 168.0 Training loss: 0.4935 Explore P: 0.0711\n",
      "Episode: 622 Total reward: 105.0 Training loss: 0.7534 Explore P: 0.0705\n",
      "Episode: 623 Total reward: 143.0 Training loss: 16.4302 Explore P: 0.0696\n",
      "Episode: 624 Total reward: 171.0 Training loss: 0.6078 Explore P: 0.0686\n",
      "Episode: 625 Total reward: 161.0 Training loss: 0.2340 Explore P: 0.0677\n",
      "Episode: 626 Total reward: 127.0 Training loss: 0.4910 Explore P: 0.0670\n",
      "Episode: 627 Total reward: 55.0 Training loss: 0.4743 Explore P: 0.0667\n",
      "Episode: 628 Total reward: 134.0 Training loss: 0.3398 Explore P: 0.0659\n",
      "Episode: 629 Total reward: 191.0 Training loss: 0.4119 Explore P: 0.0648\n",
      "Episode: 630 Total reward: 71.0 Training loss: 0.3602 Explore P: 0.0645\n",
      "Episode: 631 Total reward: 49.0 Training loss: 350.1313 Explore P: 0.0642\n",
      "Episode: 632 Total reward: 53.0 Training loss: 0.2349 Explore P: 0.0639\n",
      "Episode: 633 Total reward: 167.0 Training loss: 0.4304 Explore P: 0.0630\n",
      "Episode: 634 Total reward: 101.0 Training loss: 0.7650 Explore P: 0.0625\n",
      "Episode: 635 Total reward: 115.0 Training loss: 0.4061 Explore P: 0.0619\n",
      "Episode: 636 Total reward: 199.0 Training loss: 112.7079 Explore P: 0.0609\n",
      "Episode: 637 Total reward: 199.0 Training loss: 0.4100 Explore P: 0.0599\n",
      "Episode: 638 Total reward: 199.0 Training loss: 0.1799 Explore P: 0.0589\n",
      "Episode: 639 Total reward: 199.0 Training loss: 0.5333 Explore P: 0.0579\n",
      "Episode: 640 Total reward: 83.0 Training loss: 0.2220 Explore P: 0.0575\n",
      "Episode: 641 Total reward: 199.0 Training loss: 0.5545 Explore P: 0.0566\n",
      "Episode: 642 Total reward: 131.0 Training loss: 27.3875 Explore P: 0.0560\n",
      "Episode: 643 Total reward: 120.0 Training loss: 0.1979 Explore P: 0.0554\n",
      "Episode: 644 Total reward: 136.0 Training loss: 0.2963 Explore P: 0.0548\n",
      "Episode: 645 Total reward: 199.0 Training loss: 0.2597 Explore P: 0.0539\n",
      "Episode: 646 Total reward: 101.0 Training loss: 0.4188 Explore P: 0.0535\n",
      "Episode: 647 Total reward: 91.0 Training loss: 0.2620 Explore P: 0.0531\n",
      "Episode: 648 Total reward: 199.0 Training loss: 0.1936 Explore P: 0.0522\n",
      "Episode: 649 Total reward: 199.0 Training loss: 0.2409 Explore P: 0.0514\n",
      "Episode: 650 Total reward: 78.0 Training loss: 0.2367 Explore P: 0.0511\n",
      "Episode: 651 Total reward: 199.0 Training loss: 60.6135 Explore P: 0.0503\n",
      "Episode: 652 Total reward: 199.0 Training loss: 0.2312 Explore P: 0.0495\n",
      "Episode: 653 Total reward: 52.0 Training loss: 0.3906 Explore P: 0.0493\n",
      "Episode: 654 Total reward: 129.0 Training loss: 0.3333 Explore P: 0.0488\n",
      "Episode: 655 Total reward: 94.0 Training loss: 0.3859 Explore P: 0.0484\n",
      "Episode: 656 Total reward: 66.0 Training loss: 0.1720 Explore P: 0.0482\n",
      "Episode: 657 Total reward: 106.0 Training loss: 0.3179 Explore P: 0.0478\n",
      "Episode: 658 Total reward: 53.0 Training loss: 0.2487 Explore P: 0.0476\n",
      "Episode: 659 Total reward: 199.0 Training loss: 0.2358 Explore P: 0.0468\n",
      "Episode: 660 Total reward: 127.0 Training loss: 0.3834 Explore P: 0.0464\n",
      "Episode: 661 Total reward: 167.0 Training loss: 0.3120 Explore P: 0.0458\n",
      "Episode: 662 Total reward: 51.0 Training loss: 0.2779 Explore P: 0.0456\n",
      "Episode: 663 Total reward: 125.0 Training loss: 165.8724 Explore P: 0.0451\n",
      "Episode: 664 Total reward: 46.0 Training loss: 0.1568 Explore P: 0.0450\n",
      "Episode: 665 Total reward: 64.0 Training loss: 0.3079 Explore P: 0.0447\n",
      "Episode: 666 Total reward: 54.0 Training loss: 0.3430 Explore P: 0.0446\n",
      "Episode: 667 Total reward: 91.0 Training loss: 2.2891 Explore P: 0.0442\n",
      "Episode: 668 Total reward: 199.0 Training loss: 0.3322 Explore P: 0.0436\n",
      "Episode: 669 Total reward: 72.0 Training loss: 0.1710 Explore P: 0.0433\n",
      "Episode: 670 Total reward: 192.0 Training loss: 23.2881 Explore P: 0.0427\n",
      "Episode: 671 Total reward: 199.0 Training loss: 0.1793 Explore P: 0.0421\n",
      "Episode: 672 Total reward: 102.0 Training loss: 0.1754 Explore P: 0.0417\n",
      "Episode: 673 Total reward: 199.0 Training loss: 0.1946 Explore P: 0.0411\n",
      "Episode: 674 Total reward: 199.0 Training loss: 0.4898 Explore P: 0.0405\n",
      "Episode: 675 Total reward: 65.0 Training loss: 0.6621 Explore P: 0.0403\n",
      "Episode: 676 Total reward: 199.0 Training loss: 0.3320 Explore P: 0.0397\n",
      "Episode: 677 Total reward: 150.0 Training loss: 0.2312 Explore P: 0.0393\n",
      "Episode: 678 Total reward: 118.0 Training loss: 0.3090 Explore P: 0.0389\n",
      "Episode: 679 Total reward: 165.0 Training loss: 10.4056 Explore P: 0.0384\n",
      "Episode: 680 Total reward: 159.0 Training loss: 0.1500 Explore P: 0.0380\n",
      "Episode: 681 Total reward: 63.0 Training loss: 0.4049 Explore P: 0.0378\n",
      "Episode: 682 Total reward: 112.0 Training loss: 0.3680 Explore P: 0.0375\n",
      "Episode: 683 Total reward: 199.0 Training loss: 0.3679 Explore P: 0.0370\n",
      "Episode: 684 Total reward: 57.0 Training loss: 0.4058 Explore P: 0.0368\n",
      "Episode: 685 Total reward: 83.0 Training loss: 0.2524 Explore P: 0.0366\n",
      "Episode: 686 Total reward: 84.0 Training loss: 0.9851 Explore P: 0.0364\n",
      "Episode: 687 Total reward: 199.0 Training loss: 0.4419 Explore P: 0.0358\n",
      "Episode: 688 Total reward: 199.0 Training loss: 0.2933 Explore P: 0.0353\n",
      "Episode: 689 Total reward: 199.0 Training loss: 0.3626 Explore P: 0.0348\n",
      "Episode: 690 Total reward: 199.0 Training loss: 0.2375 Explore P: 0.0343\n",
      "Episode: 691 Total reward: 199.0 Training loss: 0.7373 Explore P: 0.0339\n",
      "Episode: 692 Total reward: 199.0 Training loss: 0.2128 Explore P: 0.0334\n",
      "Episode: 693 Total reward: 81.0 Training loss: 232.9380 Explore P: 0.0332\n",
      "Episode: 694 Total reward: 199.0 Training loss: 0.2648 Explore P: 0.0327\n",
      "Episode: 695 Total reward: 65.0 Training loss: 0.7866 Explore P: 0.0326\n",
      "Episode: 696 Total reward: 167.0 Training loss: 0.2895 Explore P: 0.0322\n",
      "Episode: 697 Total reward: 199.0 Training loss: 0.3962 Explore P: 0.0318\n",
      "Episode: 698 Total reward: 199.0 Training loss: 0.2323 Explore P: 0.0314\n",
      "Episode: 699 Total reward: 199.0 Training loss: 0.3913 Explore P: 0.0309\n",
      "Episode: 700 Total reward: 199.0 Training loss: 0.2883 Explore P: 0.0305\n",
      "Episode: 701 Total reward: 199.0 Training loss: 29.8292 Explore P: 0.0301\n",
      "Episode: 702 Total reward: 199.0 Training loss: 0.4332 Explore P: 0.0297\n",
      "Episode: 703 Total reward: 199.0 Training loss: 0.2271 Explore P: 0.0293\n",
      "Episode: 704 Total reward: 66.0 Training loss: 0.2513 Explore P: 0.0292\n",
      "Episode: 705 Total reward: 57.0 Training loss: 0.2397 Explore P: 0.0291\n",
      "Episode: 706 Total reward: 53.0 Training loss: 0.5187 Explore P: 0.0290\n",
      "Episode: 707 Total reward: 65.0 Training loss: 0.2088 Explore P: 0.0289\n",
      "Episode: 708 Total reward: 199.0 Training loss: 0.3172 Explore P: 0.0285\n",
      "Episode: 709 Total reward: 199.0 Training loss: 0.4114 Explore P: 0.0281\n",
      "Episode: 710 Total reward: 199.0 Training loss: 0.2653 Explore P: 0.0278\n",
      "Episode: 711 Total reward: 199.0 Training loss: 0.4986 Explore P: 0.0274\n",
      "Episode: 712 Total reward: 199.0 Training loss: 0.2174 Explore P: 0.0271\n",
      "Episode: 713 Total reward: 199.0 Training loss: 0.1341 Explore P: 0.0268\n",
      "Episode: 714 Total reward: 133.0 Training loss: 0.2602 Explore P: 0.0265\n",
      "Episode: 715 Total reward: 173.0 Training loss: 0.5139 Explore P: 0.0262\n",
      "Episode: 716 Total reward: 199.0 Training loss: 0.6908 Explore P: 0.0259\n",
      "Episode: 717 Total reward: 199.0 Training loss: 0.1913 Explore P: 0.0256\n",
      "Episode: 718 Total reward: 199.0 Training loss: 0.2694 Explore P: 0.0253\n",
      "Episode: 719 Total reward: 199.0 Training loss: 0.4463 Explore P: 0.0250\n",
      "Episode: 720 Total reward: 199.0 Training loss: 0.3305 Explore P: 0.0247\n",
      "Episode: 721 Total reward: 62.0 Training loss: 0.2971 Explore P: 0.0246\n",
      "Episode: 722 Total reward: 199.0 Training loss: 0.5076 Explore P: 0.0243\n",
      "Episode: 723 Total reward: 199.0 Training loss: 0.2784 Explore P: 0.0240\n",
      "Episode: 724 Total reward: 199.0 Training loss: 0.2395 Explore P: 0.0238\n",
      "Episode: 725 Total reward: 199.0 Training loss: 0.3773 Explore P: 0.0235\n",
      "Episode: 726 Total reward: 199.0 Training loss: 0.3914 Explore P: 0.0232\n",
      "Episode: 727 Total reward: 47.0 Training loss: 0.4351 Explore P: 0.0232\n",
      "Episode: 728 Total reward: 199.0 Training loss: 0.5396 Explore P: 0.0229\n",
      "Episode: 729 Total reward: 199.0 Training loss: 0.5309 Explore P: 0.0227\n",
      "Episode: 730 Total reward: 199.0 Training loss: 0.3791 Explore P: 0.0224\n",
      "Episode: 731 Total reward: 199.0 Training loss: 0.1946 Explore P: 0.0222\n",
      "Episode: 732 Total reward: 199.0 Training loss: 0.1748 Explore P: 0.0219\n",
      "Episode: 733 Total reward: 199.0 Training loss: 0.1844 Explore P: 0.0217\n",
      "Episode: 734 Total reward: 199.0 Training loss: 0.2804 Explore P: 0.0215\n",
      "Episode: 735 Total reward: 199.0 Training loss: 201.3565 Explore P: 0.0212\n",
      "Episode: 736 Total reward: 199.0 Training loss: 0.2350 Explore P: 0.0210\n",
      "Episode: 737 Total reward: 199.0 Training loss: 0.2576 Explore P: 0.0208\n",
      "Episode: 738 Total reward: 199.0 Training loss: 244.0162 Explore P: 0.0206\n",
      "Episode: 739 Total reward: 199.0 Training loss: 0.6303 Explore P: 0.0204\n",
      "Episode: 740 Total reward: 199.0 Training loss: 0.2617 Explore P: 0.0202\n",
      "Episode: 741 Total reward: 199.0 Training loss: 0.3190 Explore P: 0.0200\n",
      "Episode: 742 Total reward: 199.0 Training loss: 0.4256 Explore P: 0.0198\n",
      "Episode: 743 Total reward: 199.0 Training loss: 0.3750 Explore P: 0.0196\n",
      "Episode: 744 Total reward: 199.0 Training loss: 0.2348 Explore P: 0.0194\n",
      "Episode: 745 Total reward: 199.0 Training loss: 0.1478 Explore P: 0.0192\n",
      "Episode: 746 Total reward: 199.0 Training loss: 0.2363 Explore P: 0.0190\n",
      "Episode: 747 Total reward: 199.0 Training loss: 190.4201 Explore P: 0.0188\n",
      "Episode: 748 Total reward: 199.0 Training loss: 0.1387 Explore P: 0.0187\n",
      "Episode: 749 Total reward: 199.0 Training loss: 0.1705 Explore P: 0.0185\n",
      "Episode: 750 Total reward: 199.0 Training loss: 0.2243 Explore P: 0.0183\n",
      "Episode: 751 Total reward: 199.0 Training loss: 0.1670 Explore P: 0.0182\n",
      "Episode: 752 Total reward: 199.0 Training loss: 0.1945 Explore P: 0.0180\n",
      "Episode: 753 Total reward: 199.0 Training loss: 0.2275 Explore P: 0.0179\n",
      "Episode: 754 Total reward: 199.0 Training loss: 0.2500 Explore P: 0.0177\n",
      "Episode: 755 Total reward: 199.0 Training loss: 0.2855 Explore P: 0.0175\n",
      "Episode: 756 Total reward: 199.0 Training loss: 216.5058 Explore P: 0.0174\n",
      "Episode: 757 Total reward: 199.0 Training loss: 0.1976 Explore P: 0.0173\n",
      "Episode: 758 Total reward: 199.0 Training loss: 0.3718 Explore P: 0.0171\n",
      "Episode: 759 Total reward: 199.0 Training loss: 0.3212 Explore P: 0.0170\n",
      "Episode: 760 Total reward: 199.0 Training loss: 0.1539 Explore P: 0.0168\n",
      "Episode: 761 Total reward: 199.0 Training loss: 0.2648 Explore P: 0.0167\n",
      "Episode: 762 Total reward: 199.0 Training loss: 0.2514 Explore P: 0.0166\n",
      "Episode: 763 Total reward: 199.0 Training loss: 211.6674 Explore P: 0.0164\n",
      "Episode: 764 Total reward: 199.0 Training loss: 222.9598 Explore P: 0.0163\n",
      "Episode: 765 Total reward: 199.0 Training loss: 0.2092 Explore P: 0.0162\n",
      "Episode: 766 Total reward: 199.0 Training loss: 0.2553 Explore P: 0.0161\n",
      "Episode: 767 Total reward: 199.0 Training loss: 0.8354 Explore P: 0.0159\n",
      "Episode: 768 Total reward: 199.0 Training loss: 0.1400 Explore P: 0.0158\n",
      "Episode: 769 Total reward: 199.0 Training loss: 0.5928 Explore P: 0.0157\n",
      "Episode: 770 Total reward: 199.0 Training loss: 0.1616 Explore P: 0.0156\n",
      "Episode: 771 Total reward: 199.0 Training loss: 0.3482 Explore P: 0.0155\n",
      "Episode: 772 Total reward: 199.0 Training loss: 0.2409 Explore P: 0.0154\n",
      "Episode: 773 Total reward: 199.0 Training loss: 0.2041 Explore P: 0.0153\n",
      "Episode: 774 Total reward: 199.0 Training loss: 0.2933 Explore P: 0.0152\n",
      "Episode: 775 Total reward: 199.0 Training loss: 0.2701 Explore P: 0.0151\n",
      "Episode: 776 Total reward: 199.0 Training loss: 0.2171 Explore P: 0.0150\n",
      "Episode: 777 Total reward: 199.0 Training loss: 0.4245 Explore P: 0.0149\n",
      "Episode: 778 Total reward: 199.0 Training loss: 0.1023 Explore P: 0.0148\n",
      "Episode: 779 Total reward: 199.0 Training loss: 0.1418 Explore P: 0.0147\n",
      "Episode: 780 Total reward: 199.0 Training loss: 0.4076 Explore P: 0.0146\n",
      "Episode: 781 Total reward: 199.0 Training loss: 0.2191 Explore P: 0.0145\n",
      "Episode: 782 Total reward: 199.0 Training loss: 0.1391 Explore P: 0.0144\n",
      "Episode: 783 Total reward: 199.0 Training loss: 0.2294 Explore P: 0.0143\n",
      "Episode: 784 Total reward: 199.0 Training loss: 235.6053 Explore P: 0.0142\n",
      "Episode: 785 Total reward: 199.0 Training loss: 0.1505 Explore P: 0.0142\n",
      "Episode: 786 Total reward: 199.0 Training loss: 0.2384 Explore P: 0.0141\n",
      "Episode: 787 Total reward: 199.0 Training loss: 0.1979 Explore P: 0.0140\n",
      "Episode: 788 Total reward: 199.0 Training loss: 0.1955 Explore P: 0.0139\n",
      "Episode: 789 Total reward: 199.0 Training loss: 0.1377 Explore P: 0.0138\n",
      "Episode: 790 Total reward: 199.0 Training loss: 0.1044 Explore P: 0.0138\n",
      "Episode: 791 Total reward: 199.0 Training loss: 0.1087 Explore P: 0.0137\n",
      "Episode: 792 Total reward: 199.0 Training loss: 0.1982 Explore P: 0.0136\n",
      "Episode: 793 Total reward: 199.0 Training loss: 0.1910 Explore P: 0.0135\n",
      "Episode: 794 Total reward: 199.0 Training loss: 0.3274 Explore P: 0.0135\n",
      "Episode: 795 Total reward: 199.0 Training loss: 0.1685 Explore P: 0.0134\n",
      "Episode: 796 Total reward: 199.0 Training loss: 0.3160 Explore P: 0.0133\n",
      "Episode: 797 Total reward: 199.0 Training loss: 0.1753 Explore P: 0.0133\n",
      "Episode: 798 Total reward: 199.0 Training loss: 0.2411 Explore P: 0.0132\n",
      "Episode: 799 Total reward: 199.0 Training loss: 0.0905 Explore P: 0.0131\n",
      "Episode: 800 Total reward: 199.0 Training loss: 0.3149 Explore P: 0.0131\n",
      "Episode: 801 Total reward: 199.0 Training loss: 0.2325 Explore P: 0.0130\n",
      "Episode: 802 Total reward: 199.0 Training loss: 0.1418 Explore P: 0.0130\n",
      "Episode: 803 Total reward: 199.0 Training loss: 0.2139 Explore P: 0.0129\n",
      "Episode: 804 Total reward: 199.0 Training loss: 0.2382 Explore P: 0.0128\n",
      "Episode: 805 Total reward: 199.0 Training loss: 0.2352 Explore P: 0.0128\n",
      "Episode: 806 Total reward: 199.0 Training loss: 0.1663 Explore P: 0.0127\n",
      "Episode: 807 Total reward: 199.0 Training loss: 0.2474 Explore P: 0.0127\n",
      "Episode: 808 Total reward: 199.0 Training loss: 225.6295 Explore P: 0.0126\n",
      "Episode: 809 Total reward: 199.0 Training loss: 0.1307 Explore P: 0.0126\n",
      "Episode: 810 Total reward: 199.0 Training loss: 0.1731 Explore P: 0.0125\n",
      "Episode: 811 Total reward: 199.0 Training loss: 0.1852 Explore P: 0.0125\n",
      "Episode: 812 Total reward: 199.0 Training loss: 0.2831 Explore P: 0.0124\n",
      "Episode: 813 Total reward: 199.0 Training loss: 0.1200 Explore P: 0.0124\n",
      "Episode: 814 Total reward: 199.0 Training loss: 0.2083 Explore P: 0.0123\n",
      "Episode: 815 Total reward: 199.0 Training loss: 243.5461 Explore P: 0.0123\n",
      "Episode: 816 Total reward: 199.0 Training loss: 0.1146 Explore P: 0.0122\n",
      "Episode: 817 Total reward: 199.0 Training loss: 0.4200 Explore P: 0.0122\n",
      "Episode: 818 Total reward: 199.0 Training loss: 264.0019 Explore P: 0.0122\n",
      "Episode: 819 Total reward: 199.0 Training loss: 0.3047 Explore P: 0.0121\n",
      "Episode: 820 Total reward: 199.0 Training loss: 0.2163 Explore P: 0.0121\n",
      "Episode: 821 Total reward: 199.0 Training loss: 0.3030 Explore P: 0.0120\n",
      "Episode: 822 Total reward: 199.0 Training loss: 201.5158 Explore P: 0.0120\n",
      "Episode: 823 Total reward: 199.0 Training loss: 0.1334 Explore P: 0.0119\n",
      "Episode: 824 Total reward: 199.0 Training loss: 0.1948 Explore P: 0.0119\n",
      "Episode: 825 Total reward: 199.0 Training loss: 225.5700 Explore P: 0.0119\n",
      "Episode: 826 Total reward: 199.0 Training loss: 0.2445 Explore P: 0.0118\n",
      "Episode: 827 Total reward: 199.0 Training loss: 0.4104 Explore P: 0.0118\n",
      "Episode: 828 Total reward: 199.0 Training loss: 0.2287 Explore P: 0.0118\n",
      "Episode: 829 Total reward: 199.0 Training loss: 0.0693 Explore P: 0.0117\n",
      "Episode: 830 Total reward: 150.0 Training loss: 0.1448 Explore P: 0.0117\n",
      "Episode: 831 Total reward: 199.0 Training loss: 0.1778 Explore P: 0.0117\n",
      "Episode: 832 Total reward: 91.0 Training loss: 0.2975 Explore P: 0.0117\n",
      "Episode: 833 Total reward: 199.0 Training loss: 0.2820 Explore P: 0.0116\n",
      "Episode: 834 Total reward: 199.0 Training loss: 0.1851 Explore P: 0.0116\n",
      "Episode: 835 Total reward: 108.0 Training loss: 0.1283 Explore P: 0.0116\n",
      "Episode: 836 Total reward: 65.0 Training loss: 0.2308 Explore P: 0.0116\n",
      "Episode: 837 Total reward: 71.0 Training loss: 0.3346 Explore P: 0.0116\n",
      "Episode: 838 Total reward: 142.0 Training loss: 0.2717 Explore P: 0.0115\n",
      "Episode: 839 Total reward: 176.0 Training loss: 0.4114 Explore P: 0.0115\n",
      "Episode: 840 Total reward: 141.0 Training loss: 250.8570 Explore P: 0.0115\n",
      "Episode: 841 Total reward: 199.0 Training loss: 0.3113 Explore P: 0.0115\n",
      "Episode: 842 Total reward: 106.0 Training loss: 0.5326 Explore P: 0.0114\n",
      "Episode: 843 Total reward: 103.0 Training loss: 0.2030 Explore P: 0.0114\n",
      "Episode: 844 Total reward: 199.0 Training loss: 0.2280 Explore P: 0.0114\n",
      "Episode: 845 Total reward: 199.0 Training loss: 0.1482 Explore P: 0.0114\n",
      "Episode: 846 Total reward: 199.0 Training loss: 0.1680 Explore P: 0.0113\n",
      "Episode: 847 Total reward: 199.0 Training loss: 0.1454 Explore P: 0.0113\n",
      "Episode: 848 Total reward: 199.0 Training loss: 0.1555 Explore P: 0.0113\n",
      "Episode: 849 Total reward: 199.0 Training loss: 0.4236 Explore P: 0.0113\n",
      "Episode: 850 Total reward: 53.0 Training loss: 0.2356 Explore P: 0.0113\n",
      "Episode: 851 Total reward: 82.0 Training loss: 0.2282 Explore P: 0.0112\n",
      "Episode: 852 Total reward: 45.0 Training loss: 0.2478 Explore P: 0.0112\n",
      "Episode: 853 Total reward: 42.0 Training loss: 0.3878 Explore P: 0.0112\n",
      "Episode: 854 Total reward: 199.0 Training loss: 0.4075 Explore P: 0.0112\n",
      "Episode: 855 Total reward: 70.0 Training loss: 0.4793 Explore P: 0.0112\n",
      "Episode: 856 Total reward: 199.0 Training loss: 0.2646 Explore P: 0.0112\n",
      "Episode: 857 Total reward: 199.0 Training loss: 199.1877 Explore P: 0.0112\n",
      "Episode: 858 Total reward: 199.0 Training loss: 0.4651 Explore P: 0.0111\n",
      "Episode: 859 Total reward: 199.0 Training loss: 0.2472 Explore P: 0.0111\n",
      "Episode: 860 Total reward: 199.0 Training loss: 271.2544 Explore P: 0.0111\n",
      "Episode: 861 Total reward: 163.0 Training loss: 0.3193 Explore P: 0.0111\n",
      "Episode: 862 Total reward: 199.0 Training loss: 0.1609 Explore P: 0.0111\n",
      "Episode: 863 Total reward: 199.0 Training loss: 0.2434 Explore P: 0.0110\n",
      "Episode: 864 Total reward: 199.0 Training loss: 0.4082 Explore P: 0.0110\n",
      "Episode: 865 Total reward: 199.0 Training loss: 0.2849 Explore P: 0.0110\n",
      "Episode: 866 Total reward: 199.0 Training loss: 269.9724 Explore P: 0.0110\n",
      "Episode: 867 Total reward: 199.0 Training loss: 0.2882 Explore P: 0.0110\n",
      "Episode: 868 Total reward: 199.0 Training loss: 0.3173 Explore P: 0.0109\n",
      "Episode: 869 Total reward: 199.0 Training loss: 11.2916 Explore P: 0.0109\n",
      "Episode: 870 Total reward: 199.0 Training loss: 0.2212 Explore P: 0.0109\n",
      "Episode: 871 Total reward: 199.0 Training loss: 0.1922 Explore P: 0.0109\n",
      "Episode: 872 Total reward: 199.0 Training loss: 0.2031 Explore P: 0.0109\n",
      "Episode: 873 Total reward: 199.0 Training loss: 123.1163 Explore P: 0.0108\n",
      "Episode: 874 Total reward: 199.0 Training loss: 0.1465 Explore P: 0.0108\n",
      "Episode: 875 Total reward: 199.0 Training loss: 0.4450 Explore P: 0.0108\n",
      "Episode: 876 Total reward: 199.0 Training loss: 0.4225 Explore P: 0.0108\n",
      "Episode: 877 Total reward: 199.0 Training loss: 0.1840 Explore P: 0.0108\n",
      "Episode: 878 Total reward: 199.0 Training loss: 312.3542 Explore P: 0.0108\n",
      "Episode: 879 Total reward: 199.0 Training loss: 0.3050 Explore P: 0.0107\n",
      "Episode: 880 Total reward: 199.0 Training loss: 0.2227 Explore P: 0.0107\n",
      "Episode: 881 Total reward: 199.0 Training loss: 125.5475 Explore P: 0.0107\n",
      "Episode: 882 Total reward: 199.0 Training loss: 0.3477 Explore P: 0.0107\n",
      "Episode: 883 Total reward: 199.0 Training loss: 0.5107 Explore P: 0.0107\n",
      "Episode: 884 Total reward: 199.0 Training loss: 0.2083 Explore P: 0.0107\n",
      "Episode: 885 Total reward: 199.0 Training loss: 0.2575 Explore P: 0.0107\n",
      "Episode: 886 Total reward: 199.0 Training loss: 0.1576 Explore P: 0.0107\n",
      "Episode: 887 Total reward: 199.0 Training loss: 0.4419 Explore P: 0.0106\n",
      "Episode: 888 Total reward: 199.0 Training loss: 308.2753 Explore P: 0.0106\n",
      "Episode: 889 Total reward: 199.0 Training loss: 0.4584 Explore P: 0.0106\n",
      "Episode: 890 Total reward: 199.0 Training loss: 0.3498 Explore P: 0.0106\n",
      "Episode: 891 Total reward: 199.0 Training loss: 315.7325 Explore P: 0.0106\n",
      "Episode: 892 Total reward: 199.0 Training loss: 0.4759 Explore P: 0.0106\n",
      "Episode: 893 Total reward: 199.0 Training loss: 1.0010 Explore P: 0.0106\n",
      "Episode: 894 Total reward: 199.0 Training loss: 0.7456 Explore P: 0.0106\n",
      "Episode: 895 Total reward: 199.0 Training loss: 0.3503 Explore P: 0.0105\n",
      "Episode: 896 Total reward: 199.0 Training loss: 0.6224 Explore P: 0.0105\n",
      "Episode: 897 Total reward: 199.0 Training loss: 29.5132 Explore P: 0.0105\n",
      "Episode: 898 Total reward: 199.0 Training loss: 0.3204 Explore P: 0.0105\n",
      "Episode: 899 Total reward: 199.0 Training loss: 0.2469 Explore P: 0.0105\n",
      "Episode: 900 Total reward: 199.0 Training loss: 0.0853 Explore P: 0.0105\n",
      "Episode: 901 Total reward: 199.0 Training loss: 0.4938 Explore P: 0.0105\n",
      "Episode: 902 Total reward: 199.0 Training loss: 0.1719 Explore P: 0.0105\n",
      "Episode: 903 Total reward: 199.0 Training loss: 0.3563 Explore P: 0.0105\n",
      "Episode: 904 Total reward: 199.0 Training loss: 0.3575 Explore P: 0.0105\n",
      "Episode: 905 Total reward: 199.0 Training loss: 0.3911 Explore P: 0.0104\n",
      "Episode: 906 Total reward: 199.0 Training loss: 0.4721 Explore P: 0.0104\n",
      "Episode: 907 Total reward: 199.0 Training loss: 0.3141 Explore P: 0.0104\n",
      "Episode: 908 Total reward: 199.0 Training loss: 0.2560 Explore P: 0.0104\n",
      "Episode: 909 Total reward: 199.0 Training loss: 0.1902 Explore P: 0.0104\n",
      "Episode: 910 Total reward: 199.0 Training loss: 0.2907 Explore P: 0.0104\n",
      "Episode: 911 Total reward: 199.0 Training loss: 0.5288 Explore P: 0.0104\n",
      "Episode: 912 Total reward: 199.0 Training loss: 0.3514 Explore P: 0.0104\n",
      "Episode: 913 Total reward: 199.0 Training loss: 0.2083 Explore P: 0.0104\n",
      "Episode: 914 Total reward: 199.0 Training loss: 0.2938 Explore P: 0.0104\n",
      "Episode: 915 Total reward: 199.0 Training loss: 0.2114 Explore P: 0.0104\n",
      "Episode: 916 Total reward: 199.0 Training loss: 0.2174 Explore P: 0.0104\n",
      "Episode: 917 Total reward: 199.0 Training loss: 0.2362 Explore P: 0.0104\n",
      "Episode: 918 Total reward: 199.0 Training loss: 0.2655 Explore P: 0.0103\n",
      "Episode: 919 Total reward: 199.0 Training loss: 0.3780 Explore P: 0.0103\n",
      "Episode: 920 Total reward: 199.0 Training loss: 0.3457 Explore P: 0.0103\n",
      "Episode: 921 Total reward: 199.0 Training loss: 0.3772 Explore P: 0.0103\n",
      "Episode: 922 Total reward: 199.0 Training loss: 0.1572 Explore P: 0.0103\n",
      "Episode: 923 Total reward: 199.0 Training loss: 0.3083 Explore P: 0.0103\n",
      "Episode: 924 Total reward: 199.0 Training loss: 0.1994 Explore P: 0.0103\n",
      "Episode: 925 Total reward: 199.0 Training loss: 0.1800 Explore P: 0.0103\n",
      "Episode: 926 Total reward: 199.0 Training loss: 0.2589 Explore P: 0.0103\n",
      "Episode: 927 Total reward: 199.0 Training loss: 0.4257 Explore P: 0.0103\n",
      "Episode: 928 Total reward: 199.0 Training loss: 0.2800 Explore P: 0.0103\n",
      "Episode: 929 Total reward: 199.0 Training loss: 0.1968 Explore P: 0.0103\n",
      "Episode: 930 Total reward: 199.0 Training loss: 0.2869 Explore P: 0.0103\n",
      "Episode: 931 Total reward: 199.0 Training loss: 0.2854 Explore P: 0.0103\n",
      "Episode: 932 Total reward: 199.0 Training loss: 0.3501 Explore P: 0.0103\n",
      "Episode: 933 Total reward: 199.0 Training loss: 0.2796 Explore P: 0.0103\n",
      "Episode: 934 Total reward: 199.0 Training loss: 0.2158 Explore P: 0.0103\n",
      "Episode: 935 Total reward: 199.0 Training loss: 0.2609 Explore P: 0.0102\n",
      "Episode: 936 Total reward: 199.0 Training loss: 0.2531 Explore P: 0.0102\n",
      "Episode: 937 Total reward: 199.0 Training loss: 0.2539 Explore P: 0.0102\n",
      "Episode: 938 Total reward: 199.0 Training loss: 0.2518 Explore P: 0.0102\n",
      "Episode: 939 Total reward: 199.0 Training loss: 0.3801 Explore P: 0.0102\n",
      "Episode: 940 Total reward: 199.0 Training loss: 0.2711 Explore P: 0.0102\n",
      "Episode: 941 Total reward: 199.0 Training loss: 0.4457 Explore P: 0.0102\n",
      "Episode: 942 Total reward: 199.0 Training loss: 0.2795 Explore P: 0.0102\n",
      "Episode: 943 Total reward: 199.0 Training loss: 0.3426 Explore P: 0.0102\n",
      "Episode: 944 Total reward: 199.0 Training loss: 0.5996 Explore P: 0.0102\n",
      "Episode: 945 Total reward: 199.0 Training loss: 0.3308 Explore P: 0.0102\n",
      "Episode: 946 Total reward: 199.0 Training loss: 0.2778 Explore P: 0.0102\n",
      "Episode: 947 Total reward: 199.0 Training loss: 0.2233 Explore P: 0.0102\n",
      "Episode: 948 Total reward: 199.0 Training loss: 0.3270 Explore P: 0.0102\n",
      "Episode: 949 Total reward: 199.0 Training loss: 0.3474 Explore P: 0.0102\n",
      "Episode: 950 Total reward: 199.0 Training loss: 0.3276 Explore P: 0.0102\n",
      "Episode: 951 Total reward: 199.0 Training loss: 256.5403 Explore P: 0.0102\n",
      "Episode: 952 Total reward: 199.0 Training loss: 0.3262 Explore P: 0.0102\n",
      "Episode: 953 Total reward: 199.0 Training loss: 0.2328 Explore P: 0.0102\n",
      "Episode: 954 Total reward: 199.0 Training loss: 0.4501 Explore P: 0.0102\n",
      "Episode: 955 Total reward: 199.0 Training loss: 0.2924 Explore P: 0.0102\n",
      "Episode: 956 Total reward: 199.0 Training loss: 0.2703 Explore P: 0.0102\n",
      "Episode: 957 Total reward: 199.0 Training loss: 0.2384 Explore P: 0.0102\n",
      "Episode: 958 Total reward: 199.0 Training loss: 0.8134 Explore P: 0.0102\n",
      "Episode: 959 Total reward: 199.0 Training loss: 0.2824 Explore P: 0.0102\n",
      "Episode: 960 Total reward: 199.0 Training loss: 238.1220 Explore P: 0.0101\n",
      "Episode: 961 Total reward: 199.0 Training loss: 0.3205 Explore P: 0.0101\n",
      "Episode: 962 Total reward: 199.0 Training loss: 0.2394 Explore P: 0.0101\n",
      "Episode: 963 Total reward: 199.0 Training loss: 0.3392 Explore P: 0.0101\n",
      "Episode: 964 Total reward: 199.0 Training loss: 0.3023 Explore P: 0.0101\n",
      "Episode: 965 Total reward: 199.0 Training loss: 235.3234 Explore P: 0.0101\n",
      "Episode: 966 Total reward: 199.0 Training loss: 0.3428 Explore P: 0.0101\n",
      "Episode: 967 Total reward: 199.0 Training loss: 0.2366 Explore P: 0.0101\n",
      "Episode: 968 Total reward: 199.0 Training loss: 0.3911 Explore P: 0.0101\n",
      "Episode: 969 Total reward: 199.0 Training loss: 0.2213 Explore P: 0.0101\n",
      "Episode: 970 Total reward: 199.0 Training loss: 0.2846 Explore P: 0.0101\n",
      "Episode: 971 Total reward: 199.0 Training loss: 0.3565 Explore P: 0.0101\n",
      "Episode: 972 Total reward: 199.0 Training loss: 0.3785 Explore P: 0.0101\n",
      "Episode: 973 Total reward: 199.0 Training loss: 0.1809 Explore P: 0.0101\n",
      "Episode: 974 Total reward: 199.0 Training loss: 0.1843 Explore P: 0.0101\n",
      "Episode: 975 Total reward: 199.0 Training loss: 0.3195 Explore P: 0.0101\n",
      "Episode: 976 Total reward: 199.0 Training loss: 0.4321 Explore P: 0.0101\n",
      "Episode: 977 Total reward: 199.0 Training loss: 0.3969 Explore P: 0.0101\n",
      "Episode: 978 Total reward: 199.0 Training loss: 0.2600 Explore P: 0.0101\n",
      "Episode: 979 Total reward: 199.0 Training loss: 0.3017 Explore P: 0.0101\n",
      "Episode: 980 Total reward: 199.0 Training loss: 0.2274 Explore P: 0.0101\n",
      "Episode: 981 Total reward: 199.0 Training loss: 248.2400 Explore P: 0.0101\n",
      "Episode: 982 Total reward: 199.0 Training loss: 0.2169 Explore P: 0.0101\n",
      "Episode: 983 Total reward: 199.0 Training loss: 0.2458 Explore P: 0.0101\n",
      "Episode: 984 Total reward: 199.0 Training loss: 0.2558 Explore P: 0.0101\n",
      "Episode: 985 Total reward: 199.0 Training loss: 0.2519 Explore P: 0.0101\n",
      "Episode: 986 Total reward: 199.0 Training loss: 0.2282 Explore P: 0.0101\n",
      "Episode: 987 Total reward: 199.0 Training loss: 0.1939 Explore P: 0.0101\n",
      "Episode: 988 Total reward: 199.0 Training loss: 0.1137 Explore P: 0.0101\n",
      "Episode: 989 Total reward: 199.0 Training loss: 0.3136 Explore P: 0.0101\n",
      "Episode: 990 Total reward: 199.0 Training loss: 236.3008 Explore P: 0.0101\n",
      "Episode: 991 Total reward: 199.0 Training loss: 0.3348 Explore P: 0.0101\n",
      "Episode: 992 Total reward: 199.0 Training loss: 0.2485 Explore P: 0.0101\n",
      "Episode: 993 Total reward: 199.0 Training loss: 235.8565 Explore P: 0.0101\n",
      "Episode: 994 Total reward: 199.0 Training loss: 233.1541 Explore P: 0.0101\n",
      "Episode: 995 Total reward: 199.0 Training loss: 0.3064 Explore P: 0.0101\n",
      "Episode: 996 Total reward: 199.0 Training loss: 0.2231 Explore P: 0.0101\n",
      "Episode: 997 Total reward: 199.0 Training loss: 227.5691 Explore P: 0.0101\n",
      "Episode: 998 Total reward: 199.0 Training loss: 205.0452 Explore P: 0.0101\n",
      "Episode: 999 Total reward: 199.0 Training loss: 0.2470 Explore P: 0.0101\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "rewards_list = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    step = 0\n",
    "    for ep in range(1, train_episodes):\n",
    "        total_reward = 0\n",
    "        t = 0\n",
    "        while t < max_steps:\n",
    "            step += 1\n",
    "            # env.render()\n",
    "            \n",
    "            # Explore or Exploit\n",
    "            explore_p = explore_stop + (explore_start - explore_stop)*np.exp(-decay_rate*step) \n",
    "            if explore_p > np.random.rand():\n",
    "                # Make a random action\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # Get action from Q-network\n",
    "                feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
    "                Qs = sess.run(mainQN.output, feed_dict = feed)\n",
    "                action = np.argmax(Qs)\n",
    "                \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "            total_reward += reward\n",
    "        \n",
    "            if done:\n",
    "                # the episode ends so no next state\n",
    "                next_state = np.zeros(state.shape)\n",
    "                t = max_steps\n",
    "                \n",
    "                print('Episode: {}'.format(ep),\n",
    "                      'Total reward: {}'.format(total_reward),\n",
    "                      'Training loss: {:.4f}'.format(loss),\n",
    "                      'Explore P: {:.4f}'.format(explore_p))\n",
    "                rewards_list.append((ep, total_reward))\n",
    "                \n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                \n",
    "                # Start new episode\n",
    "                env.reset()\n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "            else:\n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                state = next_state\n",
    "                t += 1\n",
    "            \n",
    "            # sample mini-batch from memory\n",
    "            batch = memory.sample(batch_size)\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            rewards = np.array([each[2] for each in batch])\n",
    "            next_states = np.array([each[3] for each in batch])\n",
    "            \n",
    "            # Train network\n",
    "            target_Qs = sess.run(mainQN.output, feed_dict={mainQN.inputs_: next_states})\n",
    "            \n",
    "            # Set target_Qs to 0 for states where episode ends\n",
    "            episode_ends = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "            target_Qs[episode_ends] = (0, 0)\n",
    "            \n",
    "            targets = rewards + gamma * np.max(target_Qs, axis=1)\n",
    "\n",
    "            loss, _ = sess.run([mainQN.loss, mainQN.opt],\n",
    "                                feed_dict={mainQN.inputs_: states,\n",
    "                                           mainQN.targetQs_: targets,\n",
    "                                           mainQN.actions_: actions})\n",
    "        \n",
    "    saver.save(sess, \"checkpoints/cartpole.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11d826c50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d7ff438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, rews = np.array(rewards_list).T\n",
    "smoothed_rews = running_mean(rews, 10)\n",
    "plt.plot(eps[-len(smoothed_rews):], smoothed_rews)\n",
    "plt.plot(eps, rews, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_episodes = 10\n",
    "test_max_steps = 400\n",
    "env.reset()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    for ep in range(1, test_episodes):\n",
    "        t = 0\n",
    "        while t < test_max_steps:\n",
    "            env.render() \n",
    "            \n",
    "            # Get action from Q-network\n",
    "            feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
    "            Qs = sess.run(mainQN.output, feed_dict=feed)\n",
    "            action = np.argmax(Qs)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            if done:\n",
    "                t = test_max_steps\n",
    "                env.reset()\n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "            else:\n",
    "                state = next_state\n",
    "                t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dlnd-tf-lab]",
   "language": "python",
   "name": "conda-env-dlnd-tf-lab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
